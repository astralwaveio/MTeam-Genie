#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import html
import json
import logging
import os
import re
import sys
import time
import unicodedata
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import Optional, Dict, Any, List, Tuple, Set, Union

import pytz
import requests
from dateutil import parser as date_parser
from telegram import Bot
from telegram.constants import ParseMode
from telegram.error import TelegramError

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s:%(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# Global constant for category data
CATEGORY_JSON_DATA = """
{"movie":["401","419","420","421","439"],"music":["406","434"],"list":[{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-26 23:50:33","id":"100","order":"1","nameChs":"ç”µå½±","nameCht":"é›»å½±","nameEng":"Movie","image":"","parent":null},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-05-22 13:05:21","id":"423","order":"1","nameChs":"PCæ¸¸æˆ","nameCht":"PCéŠæˆ²","nameEng":"PCGame","image":"game-pc-3.jpeg","parent":"447"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2025-05-01 12:09:56","id":"427","order":"1","nameChs":"é›»å­æ›¸","nameCht":"é›»å­æ›¸","nameEng":"E-Book","image":"ebook-4.png","parent":"450"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"401","order":"1","nameChs":"ç”µå½±/SD","nameCht":"é›»å½±/SD","nameEng":"Movie/SD","image":"moviesd.png","parent":"100"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:52:09","id":"434","order":"1","nameChs":"Music(æ— æŸ)","nameCht":"Music(ç„¡æ)","nameEng":"Music(Lossless)","image":"flac.png","parent":"110"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:50:37","id":"403","order":"1","nameChs":"å½±å‰§/ç»¼è‰º/SD","nameCht":"å½±åŠ‡/ç¶œè—/SD","nameEng":"TV Series/SD","image":"tvsd.png","parent":"105"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:52:05","id":"404","order":"1","nameChs":"çºªå½•","nameCht":"ç´€éŒ„","nameEng":"Record","image":"bbc.png","parent":"444"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 17:25:00","id":"405","order":"1","nameChs":"åŠ¨ç”»","nameCht":"å‹•ç•«","nameEng":"Anime","image":"anime.png","parent":"449"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 17:25:04","id":"407","order":"1","nameChs":"è¿åŠ¨","nameCht":"é‹å‹•","nameEng":"Sports","image":"sport.png","parent":"450"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"419","order":"2","nameChs":"ç”µå½±/HD","nameCht":"é›»å½±/HD","nameEng":"Movie/HD","image":"moviehd.png","parent":"100"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 17:25:06","id":"422","order":"2","nameChs":"è½¯ä»¶","nameCht":"è»Ÿé«”","nameEng":"Software","image":"software.png","parent":"450"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:50:42","id":"402","order":"2","nameChs":"å½±å‰§/ç»¼è‰º/HD","nameCht":"å½±åŠ‡/ç¶œè—/HD","nameEng":"TV Series/HD","image":"tvhd.png","parent":"105"},{"createdDate":"2024-04-13 17:16:22","lastModifiedDate":"2024-04-13 17:16:31","id":"448","order":"2","nameChs":"TVéŠæˆ²","nameCht":"TVéŠæˆ²","nameEng":"TvGame","image":"pcgame.png","parent":"447"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-26 23:50:36","id":"105","order":"2","nameChs":"å½±å‰§/ç»¼è‰º","nameCht":"å½±åŠ‡/ç¶œè—","nameEng":"TV Series","image":"","parent":null},{"createdDate":"2024-04-13 02:03:17","lastModifiedDate":"2024-06-15 02:26:21","id":"442","order":"3","nameChs":"æœ‰è²æ›¸","nameCht":"æœ‰è²æ›¸","nameEng":"AuiBook","image":"Study_Audio.png","parent":"450"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:50:45","id":"438","order":"3","nameChs":"å½±å‰§/ç»¼è‰º/BD","nameCht":"å½±åŠ‡/ç¶œè—/BD","nameEng":"TV Series/BD","image":"tvbd.png","parent":"105"},{"createdDate":"2024-04-13 16:40:33","lastModifiedDate":"2024-04-13 16:40:33","id":"444","order":"3","nameChs":"ç´€éŒ„","nameCht":"ç´€éŒ„","nameEng":"BBC","image":null,"parent":null},{"createdDate":"2025-05-03 14:22:10","lastModifiedDate":"2025-05-03 16:55:12","id":"451","order":"3","nameChs":"æ•™è‚²å½±ç‰‡","nameCht":"æ•™è‚²å½±ç‰‡","nameEng":"æ•™è‚²å½±ç‰‡","image":"Study_Video.png","parent":"450"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:52:15","id":"406","order":"3","nameChs":"æ¼”å”±","nameCht":"æ¼”å”±","nameEng":"MV","image":"mv.png","parent":"110"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"420","order":"3","nameChs":"ç”µå½±/DVDiSo","nameCht":"é›»å½±/DVDiSo","nameEng":"Movie/DVDiSo","image":"moviedvd.png","parent":"100"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 16:50:26","id":"435","order":"4","nameChs":"å½±å‰§/ç»¼è‰º/DVDiSo","nameCht":"å½±åŠ‡/ç¶œè—/DVDiSo","nameEng":"TV Series/DVDiSo","image":"tvdvd.png","parent":"105"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-26 23:50:49","id":"110","order":"4","nameChs":"Music","nameCht":"Music","nameEng":"Music","image":"","parent":null},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-04-13 17:25:08","id":"409","order":"4","nameChs":"Misc(å…¶ä»–)","nameCht":"Misc(å…¶ä»–)","nameEng":"Misc(Other)","image":"other.png","parent":"450"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"421","order":"4","nameChs":"ç”µå½±/Blu-Ray","nameCht":"é›»å½±/Blu-Ray","nameEng":"Movie/Blu-Ray","image":"moviebd.png","parent":"100"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"439","order":"5","nameChs":"ç”µå½±/Remux","nameCht":"é›»å½±/Remux","nameEng":"Movie/Remux","image":"movieremux.png","parent":"100"},{"createdDate":"2024-04-13 17:15:28","lastModifiedDate":"2024-04-13 17:15:37","id":"447","order":"6","nameChs":"éŠæˆ²","nameCht":"éŠæˆ²","nameEng":"éŠæˆ²","image":null,"parent":null},{"createdDate":"2024-04-13 17:22:46","lastModifiedDate":"2024-04-13 17:22:55","id":"449","order":"7","nameChs":"å‹•æ¼«","nameCht":"å‹•æ¼«","nameEng":"Anime","image":null,"parent":null},{"createdDate":"2024-04-13 17:24:09","lastModifiedDate":"2024-04-13 17:24:09","id":"450","order":"8","nameChs":"å…¶ä»–","nameCht":"å…¶ä»–","nameEng":"å…¶ä»–","image":null,"parent":null},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-26 23:51:46","id":"115","order":"20","nameChs":"AV(æœ‰ç )","nameCht":"AV(æœ‰ç¢¼)","nameEng":"AV(æœ‰ç¢¼)","image":"","parent":null},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-26 23:51:50","id":"120","order":"21","nameChs":"AV(æ— ç )","nameCht":"AV(ç„¡ç¢¼)","nameEng":"AV(ç„¡ç¢¼)","image":"","parent":null},{"createdDate":"2024-04-13 16:52:43","lastModifiedDate":"2024-04-13 16:52:51","id":"445","order":"22","nameChs":"IV","nameCht":"IV","nameEng":"IV","image":null,"parent":null},{"createdDate":"2024-04-13 16:53:44","lastModifiedDate":"2024-04-13 16:53:44","id":"446","order":"23","nameChs":"H-ACG","nameCht":"H-ACG","nameEng":"H-ACG","image":null,"parent":null},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"410","order":"31","nameChs":"AV(æœ‰ç )/HD Censored","nameCht":"AV(æœ‰ç¢¼)/HD Censored","nameEng":"AV(æœ‰ç¢¼)/HD Censored","image":"cenhd.png","parent":"115"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"429","order":"32","nameChs":"AV(æ— ç )/HD Uncensored","nameCht":"AV(ç„¡ç¢¼)/HD Uncensored","nameEng":"AV(ç„¡ç¢¼)/HD Uncensored","image":"uenhd.png","parent":"120"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"424","order":"33","nameChs":"AV(æœ‰ç )/SD Censored","nameCht":"AV(æœ‰ç¢¼)/SD Censored","nameEng":"AV(æœ‰ç¢¼)/SD Censored","image":"censd.png","parent":"115"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"430","order":"34","nameChs":"AV(æ— ç )/SD Uncensored","nameCht":"AV(ç„¡ç¢¼)/SD Uncensored","nameEng":"AV(ç„¡ç¢¼)/SD Uncensored","image":"uensd.png","parent":"120"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"426","order":"35","nameChs":"AV(æ— ç )/DVDiSo Uncensored","nameCht":"AV(ç„¡ç¢¼)/DVDiSo Uncensored","nameEng":"AV(ç„¡ç¢¼)/DVDiSo Uncensored","image":"uendvd.png","parent":"120"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"437","order":"36","nameChs":"AV(æœ‰ç )/DVDiSo Censored","nameCht":"AV(æœ‰ç¢¼)/DVDiSo Censored","nameEng":"AV(æœ‰ç¢¼)/DVDiSo Censored","image":"cendvd.png","parent":"115"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"431","order":"37","nameChs":"AV(æœ‰ç )/Blu-Ray Censored","nameCht":"AV(æœ‰ç¢¼)/Blu-Ray Censored","nameEng":"AV(æœ‰ç¢¼)/Blu-Ray Censored","image":"cenbd.png","parent":"115"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"432","order":"38","nameChs":"AV(æ— ç )/Blu-Ray Uncensored","nameCht":"AV(ç„¡ç¢¼)/Blu-Ray Uncensored","nameEng":"AV(ç„¡ç¢¼)/Blu-Ray Uncensored","image":"uenbd.png","parent":"120"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"436","order":"39","nameChs":"AV(ç½‘ç«™)/0Day","nameCht":"AV(ç¶²ç«™)/0Day","nameEng":"AV(ç¶²ç«™)/0Day","image":"adult0day.png","parent":"120"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"425","order":"40","nameChs":"IV(å†™çœŸå½±é›†)","nameCht":"IV(å¯«çœŸå½±é›†)","nameEng":"IV/Video Collection","image":"ivvideo.png","parent":"445"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"433","order":"41","nameChs":"IV(å†™çœŸå›¾é›†)","nameCht":"IV(å¯«çœŸåœ–é›†)","nameEng":"IV/Picture Collection","image":"ivpic.png","parent":"445"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"411","order":"51","nameChs":"H-æ¸¸æˆ","nameCht":"H-éŠæˆ²","nameEng":"H-Game","image":"hgame.png","parent":"446"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"412","order":"52","nameChs":"H-åŠ¨æ¼«","nameCht":"H-å‹•ç•«","nameEng":"H-Anime","image":"hanime.png","parent":"446"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"413","order":"53","nameChs":"H-æ¼«ç”»","nameCht":"H-æ¼«ç•«","nameEng":"H-Comic","image":"hcomic.png","parent":"446"},{"createdDate":"2024-03-22 14:00:15","lastModifiedDate":"2024-03-22 14:00:15","id":"440","order":"440","nameChs":"AV(Gay)/HD","nameCht":"AV(Gay)/HD","nameEng":"AV(Gay)/HD","image":"gayhd.gif","parent":"120"}],"tvshow":["403","402","435","438"],"adult":["410","429","424","430","426","437","431","432","436","425","433","411","412","413","440"],"waterfall":["410","401","419","420","421","439","402","403","435","438","408","434","424","431","437","426","429","430","432","436","440","404","405","406","407","409","411","412","413","422","423","425","427","433","441","442","448"]}
"""


class CategoryManager:
    def __init__(self, category_json_string: str):
        self.categories_by_id: Dict[str, Dict[str, Any]] = {}
        self.categories_by_name_eng: Dict[str, Dict[str, Any]] = {}
        self.categories_by_name_chs: Dict[str, Dict[str, Any]] = {}
        self.categories_by_name_cht: Dict[str, Dict[str, Any]] = {}

        try:
            data = json.loads(category_json_string)
            category_list = data.get("list", [])
            for cat_info in category_list:
                cat_id = cat_info.get("id")
                if not cat_id:
                    continue
                self.categories_by_id[cat_id] = cat_info

                name_eng = cat_info.get("nameEng", "").strip()
                if name_eng: self.categories_by_name_eng[name_eng.lower()] = cat_info

                name_chs = cat_info.get("nameChs", "").strip()
                if name_chs: self.categories_by_name_chs[name_chs.lower()] = cat_info

                name_cht = cat_info.get("nameCht", "").strip()
                if name_cht: self.categories_by_name_cht[name_cht.lower()] = cat_info

            logger.info(f"ğŸ—‚ï¸ åˆ†ç±»ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼ŒåŠ è½½äº† {len(self.categories_by_id)} ä¸ªåˆ†ç±»æ¡ç›®ã€‚")
        except json.JSONDecodeError:
            logger.error("ğŸš« è§£æåˆ†ç±»JSONæ•°æ®å¤±è´¥ã€‚åˆ†ç±»åç§°è½¬æ¢å°†ä¸å¯ç”¨ã€‚")
        except Exception as e:
            logger.error(f"ğŸš« åˆå§‹åŒ–åˆ†ç±»ç®¡ç†å™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")

    def get_name_cht(self, identifier: str, is_id_lookup: bool = False) -> Optional[str]:
        """
        æ ¹æ®æä¾›çš„æ ‡è¯†ç¬¦ï¼ˆIDæˆ–åç§°ï¼‰è·å–ç¹ä½“ä¸­æ–‡åç§° (nameCht)ã€‚
        :param identifier: åˆ†ç±»IDæˆ–åˆ†ç±»åç§° (nameEng, nameChs, nameCht)ã€‚
        :param is_id_lookup: å¦‚æœä¸ºTrueï¼Œåˆ™å°†identifierä¸¥æ ¼è§†ä¸ºIDè¿›è¡ŒæŸ¥æ‰¾ã€‚
        :return: å¯¹åº”çš„nameChtï¼Œå¦‚æœæ‰¾ä¸åˆ°åˆ™è¿”å›Noneã€‚
        """
        if not identifier:
            return None

        cat_info: Optional[Dict[str, Any]] = None
        identifier_lower = identifier.lower()

        if is_id_lookup:
            cat_info = self.categories_by_id.get(identifier)
        else:
            cat_info = self.categories_by_name_eng.get(identifier_lower)
            if not cat_info:
                cat_info = self.categories_by_name_chs.get(identifier_lower)
            if not cat_info:
                cat_info = self.categories_by_name_cht.get(identifier_lower)
            if not cat_info and identifier in self.categories_by_id:
                cat_info = self.categories_by_id.get(identifier)

        if cat_info:
            return cat_info.get("nameCht")

        logger.debug(f"æœªèƒ½ä¸ºæ ‡è¯†ç¬¦ '{identifier}' (is_id_lookup={is_id_lookup}) æ‰¾åˆ°å¯¹åº”çš„åˆ†ç±»ä¿¡æ¯ã€‚")
        return None


class Config:
    def __init__(self):
        logger.info("âš™ï¸ åˆå§‹åŒ–é…ç½®...")

        self.RSS_URL: Optional[str] = os.environ.get("MT_RSS_URL")
        self.TG_BOT_TOKEN: Optional[str] = os.environ.get("TG_BOT_TOKEN")
        self.TG_CHAT_ID: Optional[str] = os.environ.get("TG_CHAT_ID")
        self.DATA_FILE_PATH: str = os.environ.get("DATA_FILE_PATH", "mteam/rss_monitor_data.json")
        self.LOG_LEVEL: str = os.environ.get("LOG_LEVEL", "INFO").upper()

        self.MAX_PROCESSED_IDS_HISTORY: int = 500
        self.PROCESSED_IDS_RETAIN_COUNT: int = 200
        try:
            self.MAX_PROCESSED_IDS_HISTORY = int(os.environ.get("MAX_PROCESSED_IDS_HISTORY", "500"))
            self.PROCESSED_IDS_RETAIN_COUNT = int(os.environ.get("PROCESSED_IDS_RETAIN_COUNT", "200"))
        except ValueError:
            logger.warning("MAX_PROCESSED_IDS_HISTORY æˆ– PROCESSED_IDS_RETAIN_COUNT ç¯å¢ƒå˜é‡å€¼æ— æ•ˆï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼ã€‚")

        self.TZ_INFOS: Dict[str, pytz.BaseTzInfo] = {"CST": pytz.timezone("Asia/Shanghai")}
        self.LOCAL_TIMEZONE: pytz.BaseTzInfo = pytz.timezone("Asia/Shanghai")

        self._setup_logging()
        self._validate_critical_configs()
        self._validate_history_configs()
        logger.info("ğŸ‘ é…ç½®åŠ è½½æˆåŠŸã€‚")

    def _setup_logging(self):
        try:
            logging.getLogger().setLevel(self.LOG_LEVEL)
            logger.info(f"æ—¥å¿—çº§åˆ«è®¾ç½®ä¸º: {self.LOG_LEVEL}")
        except ValueError:
            logger.warning(f"æ— æ•ˆçš„LOG_LEVEL: {self.LOG_LEVEL}. ä½¿ç”¨é»˜è®¤ INFOçº§åˆ«ã€‚")
            logging.getLogger().setLevel(logging.INFO)

    def _validate_critical_configs(self):
        critical_missing = []
        if not self.RSS_URL:
            critical_missing.append("M-Team RSSè®¢é˜…URL (MT_RSS_URL)")
        if not self.TG_BOT_TOKEN:
            critical_missing.append("Telegramæœºå™¨äººToken (TG_BOT_TOKEN)")
        if not self.TG_CHAT_ID:
            critical_missing.append("Telegramé¢‘é“ID (TG_CHAT_ID)")

        if critical_missing:
            error_msg = "ã€".join(critical_missing) + " æœªè®¾ç½®ã€‚è„šæœ¬æ— æ³•è¿è¡Œã€‚"
            logger.critical(f"ğŸš« {error_msg}")
            sys.exit(f"CRITICAL: {error_msg}")

    def _validate_history_configs(self):
        if self.PROCESSED_IDS_RETAIN_COUNT <= 0:
            logger.warning("PROCESSED_IDS_RETAIN_COUNT å¿…é¡»å¤§äº0ï¼Œå·²é‡ç½®ä¸ºé»˜è®¤å€¼200ã€‚")
            self.PROCESSED_IDS_RETAIN_COUNT = 200
        if self.MAX_PROCESSED_IDS_HISTORY < self.PROCESSED_IDS_RETAIN_COUNT:
            logger.warning(
                f"MAX_PROCESSED_IDS_HISTORY ({self.MAX_PROCESSED_IDS_HISTORY}) ä¸èƒ½å°äº PROCESSED_IDS_RETAIN_COUNT ({self.PROCESSED_IDS_RETAIN_COUNT})ã€‚å·²å°† MAX_PROCESSED_IDS_HISTORY è°ƒæ•´ä¸º {self.PROCESSED_IDS_RETAIN_COUNT * 2}.")
            self.MAX_PROCESSED_IDS_HISTORY = self.PROCESSED_IDS_RETAIN_COUNT * 2
        if self.MAX_PROCESSED_IDS_HISTORY <= 0:  # Should be caught by above, but defensive
            logger.warning("MAX_PROCESSED_IDS_HISTORY å¿…é¡»å¤§äº0ï¼Œå·²é‡ç½®ä¸ºé»˜è®¤å€¼500ã€‚")
            self.MAX_PROCESSED_IDS_HISTORY = 500
            if self.MAX_PROCESSED_IDS_HISTORY < self.PROCESSED_IDS_RETAIN_COUNT:
                self.PROCESSED_IDS_RETAIN_COUNT = min(200,
                                                      self.MAX_PROCESSED_IDS_HISTORY // 2 if self.MAX_PROCESSED_IDS_HISTORY > 1 else 1)
                if self.PROCESSED_IDS_RETAIN_COUNT <= 0: self.PROCESSED_IDS_RETAIN_COUNT = 1


class Utils:
    @staticmethod
    def clean_subtitle(text: str) -> str:
        if not text:
            return ""
        cleaned_text = re.sub(r'[^\w\s\u4e00-\u9fff\u3040-\u30ff\uac00-\ud7af.\-_]', '', text)
        cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
        return cleaned_text

    @staticmethod
    def get_current_time_localized(local_timezone: pytz.BaseTzInfo) -> datetime:
        return datetime.now(local_timezone)


class EmergencyNotifierConfig:
    def __init__(self, token: Optional[str], chat_id: Optional[str]):
        self.TG_BOT_TOKEN: Optional[str] = token
        self.TG_CHAT_ID: Optional[str] = chat_id
        self.LOCAL_TIMEZONE: pytz.BaseTzInfo = pytz.timezone("Asia/Shanghai")


class TelegramNotifier:
    def __init__(self, config: Union[Config, EmergencyNotifierConfig]):
        self.config = config
        self.bot: Optional[Bot] = None
        if self.config.TG_BOT_TOKEN and self.config.TG_CHAT_ID:
            try:
                self.bot = Bot(token=self.config.TG_BOT_TOKEN)
                logger.info("ğŸ¤– Telegramæœºå™¨äººå·²æˆåŠŸåˆå§‹åŒ–ã€‚")
            except Exception as e:
                logger.error(f"ğŸš« åˆå§‹åŒ–Telegramæœºå™¨äººå¤±è´¥: {e}")
                self.bot = None
        else:
            logger.warning("âš ï¸ Telegram BOT_TOKEN æˆ– CHAT_ID æœªé…ç½®ã€‚é€šçŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")

    @staticmethod
    def _escape_html(text: Optional[str]) -> str:
        if not isinstance(text, str): return ""
        return html.escape(text, quote=True)

    async def send_message(self, message: str, use_html: bool = True) -> bool:
        if not self.bot or not self.config.TG_CHAT_ID:
            logger.debug(f"ğŸ’¬ Telegramé€šçŸ¥è·³è¿‡ (æœªé…ç½®)ã€‚æ¶ˆæ¯: {message[:100]}...")
            return False
        try:
            chat_id_int = int(self.config.TG_CHAT_ID)
            max_len = 4096

            messages_to_send = []
            if use_html and len(message) > max_len:
                logger.warning(f"Telegram æ¶ˆæ¯è¿‡é•¿ ({len(message)} > {max_len})ï¼Œå°†è¢«æ‹†åˆ†ä¸ºå¤šæ¡å‘é€ã€‚")
                current_message_part = ""
                parts = message.split("\nğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸\n")

                if len(parts) <= 1 and "\n\n" in message and "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸" not in message:
                    parts = message.split("\n\n")
                if len(parts) <= 1 and "\n" in message and "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸" not in message and "\n\n" not in message:
                    parts = message.split("\n")

                for i, part_content in enumerate(parts):
                    part_to_add = part_content
                    is_last_part = (i == len(parts) - 1)

                    # Add appropriate separator if not the last part and separator exists in original message
                    if not is_last_part:
                        if message.count(
                                "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸") > 0 and "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸" not in part_content:
                            part_to_add += "\nğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸\n"
                        elif message.count("\n\n") > 0 and message.count(
                                "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸") == 0 and "\n\n" not in part_content:
                            part_to_add += "\n\n"
                        elif message.count("\n") > 0 and message.count(
                                "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸") == 0 and message.count(
                            "\n\n") == 0 and "\n" not in part_content:
                            part_to_add += "\n"

                    if len(current_message_part) + len(part_to_add) <= max_len:
                        current_message_part += part_to_add
                    else:
                        if current_message_part:
                            messages_to_send.append(current_message_part.strip())
                        current_message_part = part_to_add
                        if len(current_message_part) > max_len:
                            logger.warning(
                                f"æ¶ˆæ¯æ‹†åˆ†åå•ä¸ªéƒ¨åˆ†ä»ç„¶è¶…é•¿ ({len(current_message_part)} > {max_len})ï¼Œå°†è¿›è¡Œç¡¬åˆ†å‰²ã€‚")
                            for chunk_idx in range(0, len(current_message_part), max_len):
                                messages_to_send.append(current_message_part[chunk_idx: chunk_idx + max_len])
                            current_message_part = ""

                if current_message_part.strip():
                    messages_to_send.append(current_message_part.strip())
                if not messages_to_send and message:
                    logger.warning("æ¶ˆæ¯æ™ºèƒ½æ‹†åˆ†æœªèƒ½æœ‰æ•ˆåˆ†å‰²ï¼Œå°†å°è¯•æŒ‰å­—ç¬¦æ•°ç¡¬åˆ†å‰²ã€‚")
                    for i_chunk in range(0, len(message), max_len):
                        messages_to_send.append(message[i_chunk: i_chunk + max_len])
            else:
                messages_to_send = [message]

            all_sent_successfully = True
            for i, msg_chunk in enumerate(messages_to_send):
                if not msg_chunk.strip(): continue
                await self.bot.send_message(
                    chat_id=chat_id_int, text=msg_chunk,
                    parse_mode=ParseMode.HTML if use_html else None,
                    disable_web_page_preview=True
                )
                log_msg_preview = msg_chunk.replace('\n', ' ')[:100]
                logger.info(f"âœ… Telegramæ¶ˆæ¯å— {i + 1}/{len(messages_to_send)} å‘é€æˆåŠŸ (é¢„è§ˆ): {log_msg_preview}...")
                if i < len(messages_to_send) - 1:
                    await asyncio.sleep(1)
            return all_sent_successfully

        except ValueError:
            logger.error(f"ğŸš« æ— æ•ˆçš„Telegramé¢‘é“ID: '{self.config.TG_CHAT_ID}'ã€‚è¯·ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ã€‚")
        except TelegramError as e:
            logger.error(f"ğŸš« Telegramæ¶ˆæ¯å‘é€å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"ğŸš« å‘é€Telegramæ¶ˆæ¯æ—¶æ„å¤–é”™è¯¯ ({type(e).__name__}): {e}")
        return False

    def format_torrent_message(self, torrent_info: Dict[str, Any]) -> str:
        id_emoji = "ğŸ†”"
        category_emoji = "ğŸ·ï¸"
        subtitle_emoji = "ğŸ“œ"
        name_emoji = "ğŸ”—"
        size_emoji = "ğŸ’¾"
        time_emoji = "â°"

        header_parts = []
        torrent_id_val = self._escape_html(torrent_info.get('id', 'N/A'))
        header_parts.append(f"{id_emoji}[<code>{torrent_id_val}</code>]")

        category_val = self._escape_html(torrent_info.get('category', 'N/A'))
        if category_val != 'N/A':
            header_parts.append(f"{category_emoji}[{category_val}]")

        subtitle_val = self._escape_html(torrent_info.get('subtitle_cleaned', 'N/A'))
        if subtitle_val != 'N/A':
            header_parts.append(f"{subtitle_emoji}[{subtitle_val}]")

        header = "".join(header_parts)

        name = self._escape_html(torrent_info.get('torrent_name_component', 'N/A'))
        torrent_size = self._escape_html(torrent_info.get('size', 'N/A'))

        publish_time_default = Utils.get_current_time_localized(self.config.LOCAL_TIMEZONE)
        pub_time_obj = torrent_info.get('publish_time', publish_time_default)
        pub_time_str = pub_time_obj.strftime('%Y-%m-%d %H:%M:%S') if isinstance(pub_time_obj, datetime) else str(
            pub_time_obj)

        detail_link = self._escape_html(torrent_info.get('link', '#'))

        message = (
            f"{header}\n"
            f"{name_emoji} <b>èµ„æºåç§°:</b> <a href='{detail_link}'>{name}</a>\n"
            f"{size_emoji} <b>èµ„æºå¤§å°:</b> {torrent_size}\n"
            f"{time_emoji} <b>å‘å¸ƒæ—¶é—´:</b> {pub_time_str}"
        )
        return message

    def format_bulk_message(self, torrents: List[Dict[str, Any]], script_start_time: float) -> str:
        if not torrents:
            logger.info(f"â„¹ï¸ æœ¬è½®æ— æ–°ç§å­ã€‚")
            return ""

        count = len(torrents)
        message_header = f"ğŸ“¢ğŸ“¢ğŸ“¢ é¦’å¤´æœ‰æ–°ç§å•¦ï¼å¿«æ¥çœ‹çœ‹æœ‰æ²¡æœ‰ä½ å–œæ¬¢çš„ ({count}ä¸ªæ–°ç§):\n"

        messages = [message_header]
        for torrent in torrents:
            messages.append(self.format_torrent_message(torrent))

        return "\nğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸\n".join(messages)


class DataManager:
    def __init__(self, config: Config):
        self.config = config
        self.file_path = self.config.DATA_FILE_PATH
        self.data: Dict[str, Any] = {
            "all_pushed_ids": [],
            "last_pushed_batch_ids": []
        }

    def load_data(self) -> None:
        logger.info(f"ğŸ“‚ å°è¯•ä» {self.file_path} åŠ è½½æ•°æ®...")
        if not os.path.exists(self.file_path):
            logger.info(f"â„¹ï¸ æ•°æ®æ–‡ä»¶ {self.file_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºæ•°æ®ã€‚")
            self.data["all_pushed_ids"] = []
            self.data["last_pushed_batch_ids"] = []
            return

        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                loaded_json_data = json.load(f)

            if not isinstance(loaded_json_data, dict):
                logger.warning(f"âš ï¸ {self.file_path} æ•°æ®éå­—å…¸æ ¼å¼ã€‚å¤‡ä»½å¹¶è§†ä¸ºç©ºã€‚")
                self._backup_corrupted_file()
                self.data["all_pushed_ids"] = []
                self.data["last_pushed_batch_ids"] = []
                return

            self.data["all_pushed_ids"] = loaded_json_data.get("all_pushed_ids", [])
            self.data["last_pushed_batch_ids"] = loaded_json_data.get("last_pushed_batch_ids", [])

            if not isinstance(self.data["all_pushed_ids"], list):
                logger.warning("all_pushed_ids æ ¼å¼é”™è¯¯ï¼Œé‡ç½®ä¸ºç©ºåˆ—è¡¨ã€‚")
                self.data["all_pushed_ids"] = []
            if not isinstance(self.data["last_pushed_batch_ids"], list):
                logger.warning("last_pushed_batch_ids æ ¼å¼é”™è¯¯ï¼Œé‡ç½®ä¸ºç©ºåˆ—è¡¨ã€‚")
                self.data["last_pushed_batch_ids"] = []

            logger.info(f"âœ… ä» {self.file_path} åŠ è½½æ•°æ®æˆåŠŸã€‚")
            logger.debug(f"åŠ è½½ all_pushed_ids æ•°é‡: {len(self.data['all_pushed_ids'])}")
            logger.debug(f"åŠ è½½ last_pushed_batch_ids: {self.data['last_pushed_batch_ids']}")

        except json.JSONDecodeError as e:
            logger.error(f"ğŸš« ä» {self.file_path} è§£ç JSONå‡ºé”™: {e}ã€‚å¤‡ä»½å¹¶è§†ä¸ºç©ºã€‚")
            self._backup_corrupted_file()
            self.data["all_pushed_ids"] = []
            self.data["last_pushed_batch_ids"] = []
        except IOError as e:
            logger.error(f"ğŸš« æ— æ³•è¯»å–æ–‡ä»¶ {self.file_path}: {e}ã€‚")
            self.data["all_pushed_ids"] = []
            self.data["last_pushed_batch_ids"] = []
        except Exception as e:
            logger.error(f"ğŸš« åŠ è½½æ•°æ®æ—¶æ„å¤–é”™è¯¯ ({type(e).__name__}): {e}ã€‚")
            self.data["all_pushed_ids"] = []
            self.data["last_pushed_batch_ids"] = []

    def get_all_pushed_ids_set(self) -> Set[str]:
        return set(str(id_val) for id_val in self.data.get("all_pushed_ids", []))

    def get_last_pushed_batch_ids(self) -> List[str]:
        return [str(id_val) for id_val in self.data.get("last_pushed_batch_ids", [])]

    def _backup_corrupted_file(self):
        if not os.path.exists(self.file_path): return
        try:
            backup_path = self.file_path + f".corrupted_{int(time.time())}"
            os.rename(self.file_path, backup_path)
            logger.info(f"â„¹ï¸ å·²å¤‡ä»½å¯èƒ½æŸåçš„æ•°æ®æ–‡ä»¶åˆ° {backup_path}")
        except OSError as bak_err:
            logger.error(f"âš ï¸ æ— æ³•å¤‡ä»½æ•°æ®æ–‡ä»¶ {self.file_path}: {bak_err}")

    def save_data(self, all_ids_to_save: Set[str], last_batch_ids_to_save: List[str]) -> None:
        all_ids_list = sorted([str(id_val) for id_val in all_ids_to_save],
                              key=lambda x: (not x.isdigit(), int(x) if x.isdigit() else x))

        if len(all_ids_list) > self.config.MAX_PROCESSED_IDS_HISTORY:
            original_count = len(all_ids_list)
            all_ids_list = all_ids_list[-self.config.PROCESSED_IDS_RETAIN_COUNT:]
            ids_removed_count = original_count - len(all_ids_list)
            logger.info(
                f"ğŸ§¹ æ¸…ç†å·²å¤„ç†IDå†å²: ä» {original_count} æ¡ç¼©å‡åˆ° {len(all_ids_list)} æ¡ (ä¿ç•™æœ€æ–°çš„ {self.config.PROCESSED_IDS_RETAIN_COUNT} æ¡)ã€‚ç§»é™¤äº† {ids_removed_count} æ¡æ—§è®°å½•ã€‚")

        self.data["all_pushed_ids"] = all_ids_list
        self.data["last_pushed_batch_ids"] = [str(id_val) for id_val in last_batch_ids_to_save]

        logger.info(
            f"ğŸ’¾ ä¿å­˜ {len(self.data['all_pushed_ids'])} æ¡æ€»è®°å½•å’Œ {len(self.data['last_pushed_batch_ids'])} æ¡ä¸Šæ‰¹æ¬¡è®°å½•åˆ° {self.file_path}...")
        try:
            dir_name = os.path.dirname(self.file_path)
            if dir_name and not os.path.exists(dir_name):
                os.makedirs(dir_name, exist_ok=True)
                logger.info(f"åˆ›å»ºç›®å½•: {dir_name}")

            with open(self.file_path, "w", encoding="utf-8") as f:
                json.dump(self.data, f, ensure_ascii=False, indent=4)
            logger.info(f"âœ… æ•°æ®æˆåŠŸä¿å­˜åˆ° {self.file_path}ã€‚")
        except IOError as e:
            logger.error(f"ğŸš« ä¿å­˜æ•°æ®åˆ° {self.file_path} æ—¶IOé”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"ğŸš« ä¿å­˜æ•°æ®æ—¶æ„å¤–é”™è¯¯ ({type(e).__name__}): {e}")


class RSSParser:
    def __init__(self, config: Config):
        self.config = config
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        })
        self.category_manager = CategoryManager(CATEGORY_JSON_DATA)

    @staticmethod
    def _parse_mteam_title(title_full: str) -> Tuple[str, str, str, str]:
        """
        è§£æM-Teamçš„RSSæ ‡é¢˜ã€‚
        è¿”å›: (raw_category_name, subtitle_raw, name_component, size)
        """
        if not title_full:
            return "N/A", "N/A", "N/A", "N/A"

        original_brackets_with_content = re.findall(r'(\[[^]]+])', title_full)
        bracket_inner_contents = [b[1:-1] for b in original_brackets_with_content]

        raw_category_name = "N/A"
        category_original_bracket = None
        if bracket_inner_contents:
            raw_category_name = bracket_inner_contents[0].strip()
            category_original_bracket = original_brackets_with_content[0]

        size = "N/A"
        size_original_bracket = None
        size_pattern_text = r'\d+(?:\.\d+)?\s*(?:GB|MB|TB|GiB|MiB|TiB)'
        for i, content in reversed(list(enumerate(bracket_inner_contents))):
            if re.fullmatch(size_pattern_text, content.strip(), re.IGNORECASE):
                size = content.strip()
                size_original_bracket = original_brackets_with_content[i]
                break

        subtitle_raw = "N/A"
        subtitle_original_bracket = None
        tech_spec_indicators = r'\b(?:\d{3,4}p|x26[45]|HEVC|AVC|DTS|HDR|REMUX|BluRay|WEB-DL|MKV|AAC|FLAC|WEB|HDTV|SDTV|Rip|Encode|VXT|CtrlHD|WiKi|CHDBits|Series|Movie)\b'

        candidate_indices = []
        if len(bracket_inner_contents) > 1: candidate_indices.append(1)
        if len(bracket_inner_contents) > 2: candidate_indices.append(2)

        for idx in candidate_indices:
            current_content = bracket_inner_contents[idx].strip()
            current_original_bracket = original_brackets_with_content[idx]

            if current_original_bracket == category_original_bracket or \
                    current_original_bracket == size_original_bracket:
                continue

            is_tech_spec = re.search(tech_spec_indicators, current_content, re.IGNORECASE)
            is_simple_na = current_content.lower() == 'n/a'
            is_already_size = re.fullmatch(size_pattern_text, current_content, re.IGNORECASE)

            if not is_tech_spec and not is_simple_na and not is_already_size and len(current_content) > 3:
                subtitle_raw = current_content
                subtitle_original_bracket = current_original_bracket
                break

        name_component = title_full
        if category_original_bracket:
            name_component = name_component.replace(category_original_bracket, "", 1)
        if subtitle_original_bracket:
            name_component = name_component.replace(subtitle_original_bracket, "", 1)
        if size_original_bracket:
            name_component = name_component.replace(size_original_bracket, "", 1)

        name_component = re.sub(r'\s*\[N/A\]\s*$', '', name_component).strip()
        name_component = re.sub(r'\s{2,}', ' ', name_component).strip()

        if not name_component:
            name_component = title_full
            if category_original_bracket: name_component = name_component.replace(category_original_bracket, "", 1)
            if size_original_bracket: name_component = name_component.replace(size_original_bracket, "", 1)
            name_component = re.sub(r'\s*\[N/A\]\s*$', '', name_component).strip()
            name_component = re.sub(r'\s{2,}', ' ', name_component).strip()
            if not name_component: name_component = title_full

        return raw_category_name, subtitle_raw, name_component, size

    def get_feed_items(self) -> List[Dict[str, Any]]:
        if not self.config.RSS_URL:
            logger.error("ğŸš« M-Team RSS URL æœªé…ç½®ã€‚")
            return []

        logger.info(f"ğŸ“° ä»RSSæºè·å–é¡¹ç›®: {self.config.RSS_URL[:100]}...")
        xml_content: str = ""
        try:
            response = self.session.get(self.config.RSS_URL, timeout=30)
            response.raise_for_status()

            xml_content = response.text
            xml_content = "".join(
                ch for ch in xml_content if unicodedata.category(ch)[0] != "C" or ch in ('\t', '\n', '\r'))

            root = ET.fromstring(xml_content)
            rss_items = []

            for item_element in root.findall(".//item"):
                try:
                    title_full = item_element.findtext("title", "N/A").strip()
                    link = item_element.findtext("link")
                    pub_date_str = item_element.findtext("pubDate")
                    guid_element = item_element.find("guid")
                    guid = guid_element.text if guid_element is not None else link

                    if not link or not pub_date_str:
                        logger.warning(f"æ¡ç›®ç¼ºå°‘é“¾æ¥æˆ–å‘å¸ƒæ—¥æœŸï¼Œè·³è¿‡: '{title_full[:50]}...'")
                        continue

                    id_regex = r"(?:id=|details?/|detail/)(\d+)"
                    torrent_id_match = re.search(id_regex, link)
                    if not torrent_id_match and guid:
                        torrent_id_match = re.search(id_regex, guid)

                    if not torrent_id_match:
                        logger.warning(f"æ— æ³•ä»é“¾æ¥/GUIDæå–ID: {link} / {guid}. è·³è¿‡: '{title_full[:50]}...'")
                        continue
                    torrent_id = torrent_id_match.group(1)

                    # Step 1: Parse parts from the full title using the existing method.
                    raw_cat_from_title, subtitle_raw, torrent_name_component, torrent_size = self._parse_mteam_title(
                        title_full)
                    subtitle_cleaned = Utils.clean_subtitle(subtitle_raw)

                    # Step 2: Attempt to get a category identifier from a dedicated RSS tag.
                    category_id_or_name_from_tag: Optional[str] = item_element.findtext("category")

                    final_display_category_name = "N/A"

                    # Priority 1: Use ID from tag if available and numeric
                    if category_id_or_name_from_tag and category_id_or_name_from_tag.isdigit():
                        name_cht_from_id = self.category_manager.get_name_cht(category_id_or_name_from_tag,
                                                                              is_id_lookup=True)
                        if name_cht_from_id:
                            final_display_category_name = name_cht_from_id
                            logger.debug(
                                f"é¡¹ç›® {torrent_id}: ä½¿ç”¨æ¥è‡ªæ ‡ç­¾çš„åˆ†ç±»ID '{category_id_or_name_from_tag}' æ˜ å°„åˆ° '{final_display_category_name}'.")

                    # Priority 2: Use name from tag if not yet resolved and tag provided a name
                    if final_display_category_name == "N/A" and category_id_or_name_from_tag and not category_id_or_name_from_tag.isdigit():
                        name_cht_from_tag_name = self.category_manager.get_name_cht(category_id_or_name_from_tag,
                                                                                    is_id_lookup=False)
                        if name_cht_from_tag_name:
                            final_display_category_name = name_cht_from_tag_name
                            logger.debug(
                                f"é¡¹ç›® {torrent_id}: ä½¿ç”¨æ¥è‡ªæ ‡ç­¾çš„åˆ†ç±»å '{category_id_or_name_from_tag}' æ˜ å°„åˆ° '{final_display_category_name}'.")

                    # Priority 3: Use raw category name parsed from title if not yet resolved
                    if final_display_category_name == "N/A" and raw_cat_from_title and raw_cat_from_title != "N/A":
                        name_cht_from_title_parse = self.category_manager.get_name_cht(raw_cat_from_title,
                                                                                       is_id_lookup=False)
                        if name_cht_from_title_parse:
                            final_display_category_name = name_cht_from_title_parse
                            logger.debug(
                                f"é¡¹ç›® {torrent_id}: ä½¿ç”¨æ¥è‡ªæ ‡é¢˜è§£æçš„åˆ†ç±»å '{raw_cat_from_title}' æ˜ å°„åˆ° '{final_display_category_name}'.")

                    # Fallbacks if still "N/A"
                    if final_display_category_name == "N/A":
                        if raw_cat_from_title and raw_cat_from_title != "N/A":
                            final_display_category_name = raw_cat_from_title
                            logger.warning(
                                f"é¡¹ç›® {torrent_id}: æ— æ³•å°†åˆ†ç±» '{raw_cat_from_title}' (æ¥è‡ªæ ‡é¢˜) æ˜ å°„åˆ° nameChtã€‚ä½¿ç”¨åŸå§‹åç§°ã€‚")
                        elif category_id_or_name_from_tag:
                            final_display_category_name = category_id_or_name_from_tag
                            logger.warning(
                                f"é¡¹ç›® {torrent_id}: æ— æ³•å°†åˆ†ç±» '{category_id_or_name_from_tag}' (æ¥è‡ªæ ‡ç­¾) æ˜ å°„åˆ° nameChtã€‚ä½¿ç”¨åŸå§‹æ ‡ç­¾å†…å®¹ã€‚")

                    try:
                        publish_time_naive = date_parser.parse(pub_date_str, tzinfos=self.config.TZ_INFOS)
                        if publish_time_naive.tzinfo is None or publish_time_naive.tzinfo.utcoffset(
                                publish_time_naive) is None:
                            publish_time_aware = self.config.LOCAL_TIMEZONE.localize(publish_time_naive)
                        else:
                            publish_time_aware = publish_time_naive.astimezone(self.config.LOCAL_TIMEZONE)
                    except Exception as e_date:
                        logger.warning(f"è§£æç§å­ {torrent_id} å‘å¸ƒæ—¶é—´ '{pub_date_str}' å¤±è´¥: {e_date}. ä½¿ç”¨å½“å‰æ—¶é—´ã€‚")
                        publish_time_aware = Utils.get_current_time_localized(self.config.LOCAL_TIMEZONE)

                    rss_items.append({
                        "id": torrent_id,
                        "title_full": title_full,
                        "category": final_display_category_name,
                        "subtitle_raw": subtitle_raw,
                        "subtitle_cleaned": subtitle_cleaned,
                        "torrent_name_component": torrent_name_component,
                        "size": torrent_size,
                        "publish_time": publish_time_aware,
                        "link": link
                    })
                except Exception as e_item:
                    item_title_preview = item_element.findtext('title', 'N/A')[:50]
                    logger.warning(f"âš ï¸ è§£æRSSé¡¹ç›®æ—¶å‡ºé”™: {e_item}. é¡¹ç›®: '{item_title_preview}...'. è·³è¿‡è¯¥é¡¹ç›®ã€‚")

            logger.info(f"ğŸ“Š ä»RSSæºè§£æåˆ° {len(rss_items)} ä¸ªé¡¹ç›®ã€‚")
            rss_items.sort(key=lambda x: x["publish_time"], reverse=True)
            return rss_items

        except requests.exceptions.RequestException as e:
            logger.error(f"ğŸš« è·å–M-Team RSSæºå¤±è´¥: {e}.")
        except ET.ParseError as e:
            content_preview = xml_content[:500] if xml_content else "æ— æ³•è·å–å†…å®¹"
            logger.error(f"ğŸš« è§£æM-Team RSS XMLå¤±è´¥: {e}. å†…å®¹é¢„è§ˆ: '{content_preview}...'")
        except Exception as e:
            logger.error(f"ğŸš« å¤„ç†RSSæºæ—¶æœªçŸ¥é”™è¯¯ ({type(e).__name__}): {e}")
        return []


class FeedMonitor:
    def __init__(self, config: Config, notifier: TelegramNotifier, data_manager: DataManager, rss_parser: RSSParser):
        self.config = config
        self.notifier = notifier
        self.data_manager = data_manager
        self.rss_parser = rss_parser
        self.max_items_to_push = 10

    async def run(self) -> int:
        logger.info("ğŸš€ æ‰§è¡ŒRSSè®¢é˜…ç›‘æ§...")
        self.data_manager.load_data()

        initial_all_pushed_ids_set = self.data_manager.get_all_pushed_ids_set().copy()
        initial_last_pushed_batch_ids = list(self.data_manager.get_last_pushed_batch_ids())

        feed_items = self.rss_parser.get_feed_items()
        if not feed_items:
            logger.info("â„¹ï¸ RSSæºæ— é¡¹ç›®æˆ–åŠ è½½å¤±è´¥ã€‚")
            self.data_manager.save_data(initial_all_pushed_ids_set, initial_last_pushed_batch_ids)
            return 0

        genuinely_new_torrents = []
        for item in feed_items:
            item_id_str = str(item.get("id", ""))
            if not item_id_str:
                logger.warning(f"å‘ç°ä¸€ä¸ªæ²¡æœ‰IDçš„é¡¹ç›®: {item.get('title_full', 'N/A')[:30]}... è·³è¿‡ã€‚")
                continue
            if item_id_str not in initial_all_pushed_ids_set:
                genuinely_new_torrents.append(item)
            else:
                logger.debug(
                    f"ID {item_id_str} ({item.get('title_full', 'N/A')[:30]}...) å·²å­˜åœ¨äº all_pushed_ids_setï¼Œè·³è¿‡ã€‚")

        if not genuinely_new_torrents:
            logger.info("âœ… RSSæºä¸­æ‰€æœ‰é¡¹ç›®å‡å·²å¤„ç†è¿‡ã€‚")
            self.data_manager.save_data(initial_all_pushed_ids_set, initial_last_pushed_batch_ids)
            return 0

        current_batch_to_push = genuinely_new_torrents[:self.max_items_to_push]
        current_batch_ids = [str(item["id"]) for item in current_batch_to_push]

        if not current_batch_to_push:
            logger.info("â„¹ï¸ ç­›é€‰åæ— æ–°ç§å­å¯æ¨é€ã€‚")
            self.data_manager.save_data(initial_all_pushed_ids_set, initial_last_pushed_batch_ids)
            return 0

        if current_batch_ids == initial_last_pushed_batch_ids and initial_last_pushed_batch_ids:
            logger.info(f"â­ï¸ æœ¬æ¬¡é€‰å‡ºçš„æ–°ç§å­æ‰¹æ¬¡ (IDs: {current_batch_ids}) ä¸ä¸Šæ¬¡æˆåŠŸæ¨é€çš„æ‰¹æ¬¡å®Œå…¨ç›¸åŒï¼Œè·³è¿‡å‘é€ã€‚")
            self.data_manager.save_data(initial_all_pushed_ids_set, initial_last_pushed_batch_ids)
            return 0

        logger.info(f"ğŸ“¨ å‡†å¤‡æ¨é€ {len(current_batch_to_push)} ä¸ªæ–°ç§å­...")
        full_message_content = self.notifier.format_bulk_message(current_batch_to_push, time.monotonic())

        if not full_message_content:
            logger.info("â„¹ï¸ æ ¼å¼åŒ–æ¶ˆæ¯ä¸ºç©ºï¼Œæœ¬è½®ä¸å‘é€Telegramé€šçŸ¥ã€‚")
            self.data_manager.save_data(initial_all_pushed_ids_set, initial_last_pushed_batch_ids)
            return 0

        sent_successfully = await self.notifier.send_message(full_message_content)

        if sent_successfully:
            logger.info(f"âœ… {len(current_batch_to_push)} ä¸ªç§å­ä¿¡æ¯å·²å‘é€ã€‚")
            updated_all_pushed_ids_set = initial_all_pushed_ids_set.copy()
            updated_all_pushed_ids_set.update(current_batch_ids)
            self.data_manager.save_data(updated_all_pushed_ids_set, current_batch_ids)
            return len(current_batch_to_push)
        else:
            logger.error("ğŸš« å‘é€Telegramæ¶ˆæ¯å¤±è´¥ã€‚æœ¬è½®é¡¹ç›®ä¸æ ‡è®°ä¸ºå·²å¤„ç†ã€‚")
            self.data_manager.save_data(initial_all_pushed_ids_set, initial_last_pushed_batch_ids)
            return 0


async def main():
    script_start_time = time.monotonic()
    error_occurred_in_run = False
    items_pushed_this_run = 0

    config_instance: Optional[Config] = None
    notifier_instance: Optional[TelegramNotifier] = None

    try:
        config_instance = Config()
        notifier_instance = TelegramNotifier(config_instance)

        data_manager = DataManager(config_instance)
        rss_parser = RSSParser(config_instance)

        monitor = FeedMonitor(config_instance, notifier_instance, data_manager, rss_parser)
        items_pushed_this_run = await monitor.run()

        if items_pushed_this_run > 0:
            logger.info(f"âœ… æœ¬è½®æˆåŠŸæ¨é€ {items_pushed_this_run} ä¸ªæ–°ç§å­ã€‚")

    except SystemExit as e:
        logger.critical(f"ğŸš« é…ç½®é”™è¯¯å¯¼è‡´ä¸­æ­¢: {e}")
        error_occurred_in_run = True
        temp_tg_token_exit = os.environ.get("TG_BOT_TOKEN")
        temp_tg_chat_id_exit = os.environ.get("TG_CHAT_ID")
        if temp_tg_token_exit and temp_tg_chat_id_exit:
            emergency_config_exit = EmergencyNotifierConfig(temp_tg_token_exit, temp_tg_chat_id_exit)
            emergency_notifier_exit = TelegramNotifier(emergency_config_exit)
            if emergency_notifier_exit.bot:
                await emergency_notifier_exit.send_message(
                    f"â˜ ï¸ <b>M-Team RSSç›‘æ§</b>: ä¸¥é‡é…ç½®é”™è¯¯ä¸­æ­¢ - <code>{html.escape(str(e))}</code>. è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡ã€‚")
        return
    except Exception as e:
        logger.critical(f"ğŸš« æ‰§è¡Œæ—¶å‘ç”Ÿæœªæ•è·ä¸¥é‡é”™è¯¯ ({type(e).__name__}): {e}", exc_info=True)
        error_occurred_in_run = True
        if notifier_instance and notifier_instance.bot:
            await notifier_instance.send_message(
                f"â˜ ï¸ <b>M-Team RSSç›‘æ§</b>: è¿è¡Œæ—¶ä¸¥é‡é”™è¯¯ - <code>{html.escape(type(e).__name__)}: {html.escape(str(e)[:200])}...</code>"
            )
    finally:
        elapsed_time = time.monotonic() - script_start_time
        if error_occurred_in_run:
            logger.error(f"ğŸš« ===== è„šæœ¬å› é”™è¯¯ä¸­æ­¢æˆ–æœªå®Œæˆï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’. =====")
        else:
            logger.info(f"ğŸ‰ ===== è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’. (æ¨é€ {items_pushed_this_run} æ¡) =====")

        if notifier_instance and notifier_instance.bot:
            await asyncio.sleep(0.1)


if __name__ == "__main__":
    # os.environ[
    #     "MT_RSS_URL"] = "https://rss.m-team.cc/api/rss/fetch?dl=1&pageSize=20&sign=xxxxxxxxxxxxxxxxx&t=xxxxxxxxxxxx&teams=9%2C44%2C43%2C23&tkeys=ttitle%2Ctcat%2Ctsmalldescr%2Ctsize&uid=xxxxxxx"
    # os.environ["TG_BOT_TOKEN"] = "7888888022:TÈ›gxxxxxxxxxxxxxxxxxxxxxx"
    # os.environ["TG_CHAT_ID"] = "-10023243240"
    # os.environ["LOG_LEVEL"] = "INFO"

    required_env_vars_check = ["MT_RSS_URL", "TG_BOT_TOKEN", "TG_CHAT_ID"]
    if any(not os.environ.get(var) for var in required_env_vars_check):
        missing_vars_str = ", ".join([var for var in required_env_vars_check if not os.environ.get(var)])
        logger.critical(f"å¯åŠ¨å‰æ£€æŸ¥: å…³é”®ç¯å¢ƒå˜é‡ {missing_vars_str} æœªè®¾ç½®ã€‚è„šæœ¬æ— æ³•å¯åŠ¨ã€‚")

        temp_tg_token_main = os.environ.get("TG_BOT_TOKEN")
        temp_tg_chat_id_main = os.environ.get("TG_CHAT_ID")
        if temp_tg_token_main and temp_tg_chat_id_main:
            emergency_config_main = EmergencyNotifierConfig(temp_tg_token_main, temp_tg_chat_id_main)
            emergency_notifier_main = TelegramNotifier(emergency_config_main)
            if emergency_notifier_main.bot:
                async def notify_env_error():
                    await emergency_notifier_main.send_message(
                        f"â˜ ï¸ <b>M-Team RSSç›‘æ§</b>: å¯åŠ¨å¤±è´¥! å…³é”®ç¯å¢ƒå˜é‡ç¼ºå¤±: <code>{html.escape(missing_vars_str)}</code>")
                    await asyncio.sleep(1)


                try:
                    asyncio.run(notify_env_error())
                except Exception as e_notify:
                    logger.error(f"å‘é€ç´§æ€¥å¯åŠ¨é”™è¯¯é€šçŸ¥å¤±è´¥: {e_notify}")
        sys.exit(1)
    asyncio.run(main())
