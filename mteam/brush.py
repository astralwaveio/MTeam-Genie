#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# æ–‡ä»¶: brush.py
# æè¿°: åˆ·æµè„šæœ¬ï¼Œè‡ªåŠ¨ä» MTeam è·å–ç§å­å¹¶æ·»åŠ åˆ° qBittorrentã€‚

import asyncio
import html
import json
import logging
import os
import random
import re
import sys
import time
import unicodedata
import xml.etree.ElementTree as ET
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Union

import pytz
import requests
from dateutil import parser as date_parser
# qbittorrentapi ç›¸å…³å¯¼å…¥ï¼Œä¸å†å°è¯•å¯¼å…¥ TorrentInfo
from qbittorrentapi import Client, LoginFailed, APIConnectionError, APIError, TorrentInfoList
from telegram import Bot
from telegram.constants import ParseMode
from telegram.error import TelegramError

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(name)s - %(module)s:%(funcName)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


class Config:
    """ç®¡ç†è„šæœ¬çš„æ‰€æœ‰é…ç½®é¡¹ã€‚"""

    def __init__(self):
        logger.info("âš™ï¸ åˆå§‹åŒ–é…ç½®...")

        self.QBIT_HOST: str = os.environ.get("QBIT_HOST", "localhost")
        self.QBIT_PORT: int = int(os.environ.get("QBIT_PORT", "8080"))
        self.QBIT_USERNAME: str = os.environ.get("QBIT_USERNAME", "admin")
        self.QBIT_PASSWORD: str = os.environ.get("QBIT_PASSWORD", "adminadmin")
        qbit_tags_str: str = os.environ.get("QBIT_TAGS", "åˆ·æµ")
        self.QBIT_TAGS: List[str] = [tag.strip() for tag in qbit_tags_str.split(',') if tag.strip()]
        self.QBIT_CATEGORY: str = os.environ.get("QBIT_CATEGORY", "åˆ·æµ")
        self.QBIT_SAVE_PATH: str = os.environ.get("QBIT_SAVE_PATH", "/vol1/1000/Media/MTBrush")

        self.MT_HOST: Optional[str] = os.environ.get("MT_HOST")
        self.MT_APIKEY: Optional[str] = os.environ.get("MT_APIKEY")
        self.MT_RSS_URL: Optional[str] = os.environ.get("MT_RSS_URL")

        self.TG_BOT_TOKEN: Optional[str] = os.environ.get("TG_BOT_TOKEN")
        self.TG_CHAT_ID: Optional[str] = os.environ.get("TG_CHAT_ID")

        self.DATA_FILE_PATH: str = os.environ.get("DATA_FILE_PATH", "mteam/flood_data.json")

        self.DISK_SPACE_LIMIT_GB: float = float(os.environ.get("DISK_SPACE_LIMIT_GB", 80))
        self.MAX_TORRENT_SIZE_GB: float = float(os.environ.get("MAX_TORRENT_SIZE_GB", 30))
        self.MIN_TORRENT_SIZE_GB: float = float(os.environ.get("MIN_TORRENT_SIZE_GB", 1))
        self.SEED_FREE_TIME_HOURS: int = int(os.environ.get("SEED_FREE_TIME_HOURS", 8))
        self.SEED_PUBLISH_BEFORE_HOURS: int = int(os.environ.get("SEED_PUBLISH_BEFORE_HOURS", 24))
        self.DOWNLOADERS_TO_SEEDERS_RATIO: float = float(os.environ.get("DOWNLOADERS_TO_SEEDERS_RATIO", 1.0))
        self.USE_IPV6_DOWNLOAD: bool = os.environ.get("USE_IPV6_DOWNLOAD", "False").lower() == 'true'

        self.MAX_UNFINISHED_DOWNLOADS: int = int(os.environ.get("MAX_UNFINISHED_DOWNLOADS", 50))

        self.API_REQUEST_DELAY_MIN: float = float(os.environ.get("API_REQUEST_DELAY_MIN", 1.5))
        self.API_REQUEST_DELAY_MAX: float = float(os.environ.get("API_REQUEST_DELAY_MAX", 3.5))

        self.SEED_FREE_TIME_SECONDS: int = self.SEED_FREE_TIME_HOURS * 3600
        self.SEED_PUBLISH_BEFORE_SECONDS: int = self.SEED_PUBLISH_BEFORE_HOURS * 3600

        self.TZ_INFOS: Dict[str, pytz.BaseTzInfo] = {"CST": pytz.timezone("Asia/Shanghai")}
        self.LOCAL_TIMEZONE: pytz.BaseTzInfo = pytz.timezone("Asia/Shanghai")

        if not self.MT_HOST:
            self.MT_HOST = "https://api.m-team.cc"
            logger.info("MT_HOST æœªåœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼: https://api.m-team.cc")

        self._validate_critical_configs()
        logger.info(f"ğŸ‘ é…ç½®åŠ è½½æˆåŠŸã€‚æœªå®Œæˆä»»åŠ¡æ•°é™åˆ¶: {self.MAX_UNFINISHED_DOWNLOADS}")

    def _validate_critical_configs(self):
        critical_missing = []
        if not self.MT_APIKEY:
            critical_missing.append("MTeam APIå¯†é’¥ (MT_APIKEY)")
        if not self.MT_RSS_URL:
            critical_missing.append("MTeam RSSè®¢é˜…URL (MT_RSS_URL)")

        if critical_missing:
            error_msg = "ã€".join(critical_missing) + " æœªè®¾ç½®ã€‚è„šæœ¬æ— æ³•è¿è¡Œã€‚"
            logger.critical(f"ğŸš« {error_msg}")
            sys.exit(f"CRITICAL: {error_msg}")

        if not self.TG_BOT_TOKEN or not self.TG_CHAT_ID:
            logger.warning("âš ï¸ Telegramæœºå™¨äººToken (TG_BOT_TOKEN) æˆ–é¢‘é“ID (TG_CHAT_ID) æœªé…ç½®ã€‚é€šçŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚")


class Utils:
    @staticmethod
    def convert_gb_to_bytes(gb_size: float) -> int:
        return int(gb_size * 1024 * 1024 * 1024)

    @staticmethod
    def format_size(size_bytes: Union[int, float]) -> str:
        if not isinstance(size_bytes, (int, float)) or size_bytes < 0:
            if size_bytes == -1: return "N/A (RSS)"
            return "N/A"
        if size_bytes == 0: return "0 B"
        if size_bytes < 1024:
            return f"{size_bytes} B"
        size = float(size_bytes)
        for unit in ["KiB", "MiB", "GiB", "TiB"]:
            size /= 1024
            if size < 1024:
                return f"{size:.2f} {unit}"
        return f"{size:.2f} PiB"

    @staticmethod
    def get_current_time_localized(local_timezone: pytz.BaseTzInfo) -> datetime:
        return datetime.now(local_timezone)

    @staticmethod
    async def random_delay_async(min_delay: float, max_delay: float):
        delay = random.uniform(min_delay, max_delay)
        logger.debug(f"â³ æ‰§è¡Œ {delay:.2f} ç§’çš„å¼‚æ­¥éšæœºå»¶è¿Ÿ...")
        await asyncio.sleep(delay)


class QBittorrentManager:
    def __init__(self, config: Config):
        self.config = config
        self.client: Optional[Client] = None
        self._connect()

    def _connect(self) -> None:
        logger.info(f"ğŸ”— å°è¯•è¿æ¥åˆ° qBittorrent: {self.config.QBIT_HOST}:{self.config.QBIT_PORT}")
        conn_info = {
            "host": self.config.QBIT_HOST,
            "port": self.config.QBIT_PORT,
            "username": self.config.QBIT_USERNAME,
            "password": self.config.QBIT_PASSWORD,
            "REQUESTS_ARGS": {"timeout": (10, 30)}
        }
        try:
            self.client = Client(**conn_info)
            self.client.auth_log_in()
            logger.info(
                f"âœ… æˆåŠŸè¿æ¥å¹¶ç™»å½•åˆ° qBittorrent (ç‰ˆæœ¬: {self.client.app.version}, API ç‰ˆæœ¬: {self.client.app.web_api_version})")
        except LoginFailed as e:
            logger.critical(f"ğŸš« qBittorrent ç™»å½•å¤±è´¥: {e}. è¯·æ£€æŸ¥å‡­æ®ã€‚")
            self.client = None
            raise
        except APIConnectionError as e:
            logger.critical(f"ğŸš« æ— æ³•è¿æ¥åˆ° qBittorrent ({self.config.QBIT_HOST}:{self.config.QBIT_PORT}): {e}")
            self.client = None
            raise
        except Exception as e:
            logger.critical(f"ğŸš« åˆ›å»º qBittorrent å®¢æˆ·ç«¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ ({type(e).__name__}): {e}")
            self.client = None
            raise

    def disconnect(self) -> None:
        if self.client and self.client.is_logged_in:
            try:
                self.client.auth_log_out()
                logger.info("ğŸ”Œ å·²æˆåŠŸä» qBittorrent æ³¨é”€ã€‚")
            except Exception as e:
                logger.error(f"âš ï¸ ä» qBittorrent æ³¨é”€æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        self.client = None

    def get_free_disk_space(self) -> Optional[int]:
        if not self.client or not self.client.is_logged_in: return None
        try:
            main_data = self.client.sync_maindata()
            if main_data and hasattr(main_data.server_state, 'free_space_on_disk'):
                free_space = main_data.server_state.free_space_on_disk
                logger.info(f"ğŸ’¾ è·å–åˆ°ç£ç›˜å‰©ä½™ç©ºé—´: {Utils.format_size(free_space)}")
                return free_space
            logger.warning("âš ï¸ æ— æ³•ä» qBittorrent è·å– server_state æˆ– free_space_on_diskã€‚")
            return None
        except Exception as e:
            logger.error(f"âš ï¸ è·å–ç£ç›˜å‰©ä½™ç©ºé—´æ—¶å‡ºé”™: {e}")
            return None

    def get_unfinished_torrents_count(self) -> Optional[int]:
        """è·å–æ‰€æœ‰æœªå®Œæˆï¼ˆè¿›åº¦ < 100%ï¼‰çš„ç§å­æ•°é‡ã€‚"""
        if not self.client or not self.client.is_logged_in:
            logger.warning("âš ï¸ qBittorrent å®¢æˆ·ç«¯æœªè¿æ¥ï¼Œæ— æ³•è·å–æœªå®Œæˆä»»åŠ¡æ•°ã€‚")
            return None
        try:
            # torrents_info() è¿”å› TorrentInfoList å¯¹è±¡ï¼Œå®ƒæœ¬èº«å¯è¿­ä»£ï¼Œå…¶å…ƒç´ æ˜¯ç±»å­—å…¸å¯¹è±¡
            torrents: Optional[TorrentInfoList] = self.client.torrents_info(status_filter='all')
            unfinished_count = 0
            if torrents:
                for torrent in torrents:  # æ­¤å¤„çš„ torrent æ˜¯ä¸€ä¸ªç±»å­—å…¸å¯¹è±¡ï¼Œå¯ä»¥ç›´æ¥è®¿é—®å±æ€§
                    if torrent.progress < 1.0:
                        unfinished_count += 1
            logger.info(f"ğŸ“Š qBittorrent ä¸­å½“å‰æœªå®Œæˆçš„ä¸‹è½½ä»»åŠ¡æ•°é‡: {unfinished_count}")
            return unfinished_count
        except APIError as e:
            logger.error(f"ğŸš« è·å– qBittorrent æœªå®Œæˆä»»åŠ¡æ•°æ—¶ API å‡ºé”™: {e}")
            return None
        except Exception as e:
            logger.error(f"ğŸš« è·å– qBittorrent æœªå®Œæˆä»»åŠ¡æ•°æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ ({type(e).__name__}): {e}")
            return None

    def add_torrent_by_url(self, torrent_url: str, rename_value: Optional[str] = None) -> bool:
        if not self.client or not self.client.is_logged_in: return False
        params = {
            'urls': torrent_url,
            'save_path': self.config.QBIT_SAVE_PATH,
            'category': self.config.QBIT_CATEGORY,
            'tags': self.config.QBIT_TAGS,
            'paused': False,
            'sequentialDownload': True,
            'firstLastPiecePrio': True,
        }
        if rename_value: params['rename'] = rename_value

        log_name = rename_value if rename_value else torrent_url[:70] + "..."
        logger.info(f"â• å‡†å¤‡å‘ qBittorrent æ·»åŠ ç§å­: '{log_name}'")
        try:
            response_ok = self.client.torrents_add(**params)
            if response_ok == "Ok." or response_ok is True:
                logger.info(f"ğŸ‘ ç§å­ '{log_name}' æ·»åŠ è¯·æ±‚å·²æˆåŠŸå‘é€åˆ° qBittorrentã€‚")
                return True
            else:
                torrents_info_list: Optional[TorrentInfoList] = self.client.torrents_info(
                    status_filter='all', category=self.config.QBIT_CATEGORY
                )
                if torrents_info_list:
                    url_torrent_file_part_match = re.search(r'/([^/?]+\.torrent)', torrent_url)
                    url_identifier_for_check = url_torrent_file_part_match.group(
                        1) if url_torrent_file_part_match else torrent_url

                    for torrent_info_item in torrents_info_list:  # torrent_info_item æ˜¯ç±»å­—å…¸å¯¹è±¡
                        if (rename_value and torrent_info_item.name == rename_value) or \
                                (torrent_info_item.name in url_identifier_for_check):
                            logger.info(
                                f"â„¹ï¸ ç§å­ '{log_name}' æ·»åŠ è¯·æ±‚æœªæ˜ç¡®æˆåŠŸï¼Œä½†ä¼¼ä¹å·²å­˜åœ¨äºä¸‹è½½åˆ—è¡¨ä¸­ (åç§°åŒ¹é…: {torrent_info_item.name})ã€‚")
                            return True
                logger.warning(
                    f"ğŸ¤” ç§å­ '{log_name}' æ·»åŠ è¯·æ±‚æœªæ˜ç¡®æˆåŠŸ ({response_ok})ï¼Œä¸”æœªåœ¨åˆ—è¡¨ä¸­æ‰¾åˆ°ã€‚qBittorrent å¯èƒ½æ‹’ç»äº†å®ƒã€‚")
                return False
        except APIError as e:
            if "torrent is already in the download list" in str(e).lower() or \
                    ("failed to add torrent" in str(e).lower() and "already present" in str(e).lower()) or \
                    ("already in the session" in str(e).lower()):
                logger.info(f"â„¹ï¸ ç§å­ '{log_name}' å·²å­˜åœ¨äºä¸‹è½½åˆ—è¡¨ä¸­ (APIError: {e})ã€‚")
                return True
            logger.error(f"ğŸš« é€šè¿‡ URL æ·»åŠ ç§å­ '{log_name}' æ—¶ API å‡ºé”™: {e}")
            return False
        except Exception as e:
            logger.error(f"ğŸš« é€šè¿‡ URL æ·»åŠ ç§å­ '{log_name}' æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ ({type(e).__name__}): {e}")
            return False


class TelegramNotifier:
    def __init__(self, config: Config):
        self.config = config
        self.bot: Optional[Bot] = None
        if self.config.TG_BOT_TOKEN and self.config.TG_CHAT_ID:
            try:
                self.bot = Bot(token=self.config.TG_BOT_TOKEN)
                logger.info("ğŸ¤– Telegramæœºå™¨äººå·²æˆåŠŸåˆå§‹åŒ–ã€‚")
            except Exception as e:
                logger.error(f"ğŸš« åˆå§‹åŒ–Telegramæœºå™¨äººå¤±è´¥: {e}")
                self.bot = None
        else:
            logger.warning("âš ï¸ Telegram BOT_TOKEN æˆ– CHAT_ID æœªé…ç½®ã€‚")

    @staticmethod
    def _escape_html(text: str) -> str:
        if not isinstance(text, str): return ""
        return html.escape(text, quote=True)

    async def send_message(self, message: str, use_html: bool = True) -> None:
        if not self.bot or not self.config.TG_CHAT_ID:
            logger.debug(f"ğŸ’¬ Telegramé€šçŸ¥è·³è¿‡ (æœªé…ç½®)ã€‚æ¶ˆæ¯: {message[:100]}...")
            return
        try:
            chat_id_int = int(self.config.TG_CHAT_ID)
            max_len = 4000
            if use_html and len(message) > max_len:
                logger.warning(f"Telegram æ¶ˆæ¯è¿‡é•¿ ({len(message)} > {max_len})ï¼Œå°†è¢«æˆªæ–­ã€‚")
                safe_cutoff = message.rfind('\n', 0, max_len - 30)
                if safe_cutoff == -1: safe_cutoff = max_len - 30
                message = message[:safe_cutoff] + "\n... (æ¶ˆæ¯è¿‡é•¿è¢«æˆªæ–­)"

            await self.bot.send_message(
                chat_id=chat_id_int, text=message,
                parse_mode=ParseMode.HTML if use_html else None,
                disable_web_page_preview=True
            )
            log_msg_preview = message.replace('\n', ' ')[:100]
            logger.info(f"âœ… Telegramæ¶ˆæ¯å‘é€æˆåŠŸ (å‰100å­—ç¬¦): {log_msg_preview}")
        except ValueError:
            logger.error(f"ğŸš« æ— æ•ˆçš„Telegramé¢‘é“ID: '{self.config.TG_CHAT_ID}'ã€‚è¯·ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ã€‚")
        except TelegramError as e:
            logger.error(f"ğŸš« Telegramæ¶ˆæ¯å‘é€å¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"ğŸš« å‘é€Telegramæ¶ˆæ¯æ—¶æ„å¤–é”™è¯¯ ({type(e).__name__}): {e}")

    def format_bulk_torrent_add_success(self, added_torrents: List[Dict[str, Any]],
                                        duration_seconds: Optional[float]) -> str | None:
        if not added_torrents:
            logger.info(f"ğŸ¤· MTeamåˆ·æµè„šæœ¬ï¼šæœ¬è½®è¿è¡Œæœªæ·»åŠ ä»»ä½•æ–°ç§å­ã€‚\nâ±ï¸ ä»»åŠ¡è€—æ—¶: {duration_seconds:.2f} ç§’")
            return None

        count = len(added_torrents)
        message_lines = [
            f"<b>ğŸ‰ MTeamåˆ·æµè„šæœ¬ï¼šæœ¬è½®æˆåŠŸæ·»åŠ  {count} ä¸ªæ–°ç§å­ï¼</b>",
            "ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸"
        ]
        for torrent_info_dict in added_torrents:  # Renamed for clarity
            name = self._escape_html(torrent_info_dict.get("name", "N/A"))
            renamed_to = self._escape_html(torrent_info_dict.get("renamed_to", "N/A"))
            size_str = Utils.format_size(torrent_info_dict.get("size_bytes", 0))
            discount = self._escape_html(torrent_info_dict.get("discount", "N/A"))
            ls_ratio = self._escape_html(torrent_info_dict.get("ls_ratio", "N/A"))
            mteam_id = torrent_info_dict.get("mteam_id", "")
            detail_url = f"https://kp.m-team.cc/detail/{mteam_id}" if mteam_id else "#"

            entry = (
                f"ğŸ”— <a href='{detail_url}'><b>{name[:60]}...</b></a>\n"
                f"â†³ ğŸ·ï¸ {renamed_to[:60]}...\n"
                f"  ğŸ’¾ {size_str} | ğŸ {discount} | ğŸ“Š {ls_ratio}"
            )
            message_lines.append(entry)
            message_lines.append("ğŸŒ¸â–â–â–â–â–â–â–â–ğŸŒ¸")

        if duration_seconds is not None:
            message_lines.append(f"â±ï¸ <b>ä»»åŠ¡æ€»è€—æ—¶:</b> {duration_seconds:.2f} ç§’")
        return "\n".join(message_lines)

    def format_script_status(self, status: str, details: Optional[str] = None) -> str | None:
        if status == "start":
            logger.info(f"ğŸš€ MTeamåˆ·æµè„šæœ¬: ä»»åŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…æ·»åŠ ç§å­ ... ")
            return None
        elif status == "error":
            escaped_details = self._escape_html(details) if details else "æœªçŸ¥é”™è¯¯"
            return f"<b>â˜ ï¸ MTeamåˆ·æµè„šæœ¬:</b> ä¸¥é‡é”™è¯¯ - {escaped_details}ã€‚è„šæœ¬ä¸­æ­¢ã€‚"
        elif status == "warning_disk_space":
            escaped_details = self._escape_html(details) if details else "ç£ç›˜ç©ºé—´ä¸è¶³"
            return f"<b>ğŸ“‰ MTeamåˆ·æµè„šæœ¬è­¦å‘Š:</b> {escaped_details}"
        return self._escape_html(status)

    @staticmethod
    def format_max_unfinished_torrents_warning(count: int, limit: int) -> str:
        return (f"<b>âš ï¸ MTeamåˆ·æµè„šæœ¬è­¦å‘Š:</b>\n\n"
                f"æ£€æµ‹åˆ° qBittorrent ä¸­æœªå®Œæˆçš„ä¸‹è½½ä»»åŠ¡æ•°é‡ (<b>{count}</b>) "
                f"å·²è¶…è¿‡è®¾å®šçš„é™åˆ¶ (<b>{limit}</b>)ã€‚\n\n"
                f"ä¸ºäº†é¿å… qBittorrent è´Ÿè½½è¿‡é«˜ï¼Œæœ¬è½®åˆ·æµæ“ä½œå·²æš‚åœï¼Œå°†ä¸ä¼šæ·»åŠ æ–°çš„ç§å­ã€‚\n"
                f"è¯·æ£€æŸ¥ qBittorrent ä¸­çš„ä»»åŠ¡æƒ…å†µã€‚")


class MTeamManager:
    def __init__(self, config: Config):
        self.config = config
        if not self.config.MT_APIKEY or not self.config.MT_HOST:
            logger.critical("ğŸš« MTeam APIå¯†é’¥æˆ–ä¸»æœºæœªé…ç½®ã€‚")
            raise ValueError("MTeam API Key or Host not configured.")
        self.session = requests.Session()
        self.session.headers.update({"x-api-key": self.config.MT_APIKEY})
        logger.info("ğŸ”‘ MTeam APIä¼šè¯å·²é…ç½®ã€‚")

    def get_torrent_details(self, torrent_id: str) -> Optional[Dict[str, Any]]:
        url = f"{self.config.MT_HOST}/api/torrent/detail"
        try:
            response = self.session.post(url, data={"id": torrent_id}, timeout=20)
            response.raise_for_status()
            data = response.json()
            if data.get("message", "").upper() != 'SUCCESS' or "data" not in data:
                logger.warning(f"âš ï¸ MTeam APIæŠ¥å‘Šç§å­ {torrent_id} é—®é¢˜: {data.get('message', 'æœªçŸ¥é”™è¯¯')}.")
                return None

            torrent_data = data["data"]
            details = {
                "name": torrent_data.get("name"), "size": int(torrent_data.get("size", 0)),
                "discount": torrent_data.get("status", {}).get("discount"),
                "discount_end_time_str": torrent_data.get("status", {}).get("discountEndTime"),
                "seeders": int(torrent_data.get("status", {}).get("seeders", 0)),
                "leechers": int(torrent_data.get("status", {}).get("leechers", 0)),
                "discount_end_time": None
            }
            if not details["name"] or details["size"] is None:
                logger.warning(f"âš ï¸ ç§å­ {torrent_id} ç¼ºå°‘åç§°æˆ–å¤§å°ä¿¡æ¯ã€‚")
                return None
            if details["discount_end_time_str"]:
                try:
                    dt_naive = datetime.strptime(details["discount_end_time_str"], "%Y-%m-%d %H:%M:%S")
                    details["discount_end_time"] = self.config.LOCAL_TIMEZONE.localize(dt_naive)
                except ValueError:
                    logger.debug(f"æ— æ³•è§£æç§å­ {torrent_id} çš„ä¼˜æƒ ç»“æŸæ—¶é—´ '{details['discount_end_time_str']}'ã€‚")
            return details
        except requests.exceptions.RequestException as e:
            logger.error(f"ğŸš« è·å–MTeamç§å­ID {torrent_id} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}.")
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.error(f"ğŸš« è§£æMTeamç§å­ID {torrent_id} è¯¦ç»†ä¿¡æ¯å¤±è´¥: {e}.")
        return None

    def get_torrent_download_url(self, torrent_id: str) -> str or None:
        url = f"{self.config.MT_HOST}/api/torrent/genDlToken"
        try:
            response = self.session.post(url, data={"id": torrent_id}, timeout=20)
            response.raise_for_status()
            data = response.json()
            if data.get("message", "").upper() != 'SUCCESS' or "data" not in data or not data["data"]:
                logger.warning(f"âš ï¸ MTeam APIæ— æ³•ä¸ºç§å­ {torrent_id} ç”Ÿæˆä¸‹è½½URL: {data.get('message', 'æ— ä»¤ç‰Œ')}.")
                return None

            token_url_part = data["data"]
            if "?" in token_url_part:
                base_url, params_str = token_url_part.split("?", 1)
            else:
                base_url = token_url_part
                params_str = ""

            params = dict(p.split("=", 1) for p in params_str.split("&") if "=" in p) if params_str else {}
            params["useHttps"] = "true"
            params["type"] = "ipv6" if self.config.USE_IPV6_DOWNLOAD else "ipv4"

            final_url = base_url
            if params:
                final_url += "?" + '&'.join([f'{k}={v}' for k, v in params.items()])
            return final_url
        except requests.exceptions.RequestException as e:
            logger.error(f"ğŸš« è·å–MTeamç§å­ID {torrent_id} ä¸‹è½½URLå¤±è´¥: {e}.")
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.error(f"ğŸš« è§£æMTeamç§å­ID {torrent_id} ä¸‹è½½URLå¤±è´¥: {e}.")
        return None

    def get_rss_feed_items(self) -> List[Dict[str, Any]]:
        if not self.config.MT_RSS_URL:
            logger.error("ğŸš« MTeam RSS URL æœªé…ç½®ã€‚")
            return []
        logger.info(f"ğŸ“° æ­£åœ¨ä» RSS è®¢é˜…æºè·å–é¡¹ç›®: {self.config.MT_RSS_URL[:100]}...")
        try:
            response = self.session.get(self.config.MT_RSS_URL, timeout=45)
            response.raise_for_status()

            xml_content = response.text
            xml_content = "".join(
                ch for ch in xml_content if unicodedata.category(ch)[0] != "C" or ch in ('\t', '\n', '\r'))

            root = ET.fromstring(xml_content)
            rss_items = []
            for item_element in root.findall(".//item"):
                try:
                    link = item_element.findtext("link")
                    if not link: continue
                    torrent_id_match = re.search(r"(?:id=|detail/)(\d+)", link)
                    if not torrent_id_match: continue
                    torrent_id = torrent_id_match.group(1)

                    title = item_element.findtext("title", "N/A")
                    pub_date_str = item_element.findtext("pubDate")
                    if not pub_date_str: continue

                    bracketed_parts = re.findall(r'\[([^]]*)]', title)
                    category_rss, subtitle_rss = None, None
                    if len(bracketed_parts) >= 1: category_rss = bracketed_parts[0].strip().replace("/", "-")

                    if len(bracketed_parts) >= 2:
                        potential_subtitle = bracketed_parts[1].strip()
                        tech_spec_pattern = r'\b(?:\d{3,4}p|x26[45]|HEVC|AVC|DTS|HDR|REMUX|BluRay|WEB-DL|\d+(\.\d+)?\s*(GB|MB|TB))\b'
                        if not re.search(tech_spec_pattern, potential_subtitle, re.IGNORECASE):
                            subtitle_rss = potential_subtitle
                        elif len(bracketed_parts) >= 3:
                            potential_subtitle_2 = bracketed_parts[2].strip()
                            if not re.search(tech_spec_pattern, potential_subtitle_2, re.IGNORECASE):
                                subtitle_rss = potential_subtitle_2

                    size_bytes = -1
                    enclosure = item_element.find("enclosure")
                    if enclosure is not None and enclosure.get("length"):
                        try:
                            size_bytes = int(enclosure.get("length"))
                        except ValueError:
                            logger.debug(f"RSS item {torrent_id}: Invalid size in enclosure: {enclosure.get('length')}")

                    if size_bytes == -1 and bracketed_parts:
                        last_bracket_content = bracketed_parts[-1]
                        size_match = re.search(r"(\d+(?:\.\d+)?)\s*(B|KB|MB|GB|TB|PB)",
                                               last_bracket_content.replace("ï¼Œ", ","), re.IGNORECASE)
                        if size_match:
                            try:
                                size_value = float(size_match.group(1))
                                unit_multipliers = {"B": 1, "KB": 1024, "MB": 1024 ** 2, "GB": 1024 ** 3,
                                                    "TB": 1024 ** 4, "PB": 1024 ** 5}
                                size_unit = size_match.group(2).upper()
                                if size_unit in unit_multipliers:
                                    size_bytes = int(size_value * unit_multipliers[size_unit])
                            except ValueError:
                                logger.debug(
                                    f"RSS item {torrent_id}: Invalid size in title bracket: {last_bracket_content}")

                    rss_items.append({
                        "id": torrent_id, "title": title, "publish_time_str": pub_date_str,
                        "size_bytes_rss": size_bytes, "category_rss": category_rss, "subtitle_rss": subtitle_rss,
                    })
                except Exception as e:
                    logger.warning(
                        f"âš ï¸ è§£æRSSé¡¹ç›®æ—¶å‡ºé”™: {e}. é¡¹ç›®æ ‡é¢˜: '{item_element.findtext('title', 'N/A')[:50]}...'. è·³è¿‡æ­¤é¡¹ç›®ã€‚")
            logger.info(f"ğŸ“Š ä»RSSè®¢é˜…æºè§£æåˆ° {len(rss_items)} ä¸ªé¡¹ç›®ã€‚")
            return rss_items
        except requests.exceptions.RequestException as e:
            logger.error(f"ğŸš« è·å–MTeam RSSè®¢é˜…æºå¤±è´¥: {e}.")
        except ET.ParseError as e:
            logger.error(f"ğŸš« è§£æMTeam RSS XMLå¤±è´¥: {e}")
        except Exception as e:
            logger.error(f"ğŸš« å¤„ç†RSSè®¢é˜…æºæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return []


class DataManager:
    def __init__(self, config: Config):
        self.config = config
        self.file_path = self.config.DATA_FILE_PATH

    def load_processed_torrents(self) -> List[Dict[str, Any]]:
        logger.info(f"ğŸ“‚ å°è¯•ä» {self.file_path} åŠ è½½å·²å¤„ç†çš„ç§å­æ•°æ®...")
        if not os.path.exists(self.file_path):
            logger.info(f"â„¹ï¸ æ•°æ®æ–‡ä»¶ {self.file_path} ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°çš„ã€‚")
            return []
        try:
            with open(self.file_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            if not isinstance(data, list):
                logger.warning(f"âš ï¸ {self.file_path} ä¸­çš„æ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼ã€‚å°†å°è¯•å¤‡ä»½å¹¶è§†ä¸ºç©ºã€‚")
                self._backup_corrupted_file()
                return []
            valid_records = []
            for r in data:
                if isinstance(r, dict) and "id" in r:
                    valid_records.append(r)
                else:
                    logger.warning(f"âš ï¸ åœ¨ {self.file_path} ä¸­å‘ç°æ— æ•ˆè®°å½•: {str(r)[:100]}... å·²è·³è¿‡ã€‚")
            logger.info(f"âœ… æˆåŠŸä» {self.file_path} åŠ è½½ {len(valid_records)} æ¡æœ‰æ•ˆè®°å½•ã€‚")
            return valid_records
        except json.JSONDecodeError as e:
            logger.error(f"ğŸš« ä» {self.file_path} è§£ç JSONå‡ºé”™: {e}ã€‚å°†å°è¯•å¤‡ä»½å¹¶è§†ä¸ºç©ºã€‚")
            self._backup_corrupted_file()
        except IOError as e:
            logger.error(f"ğŸš« æ— æ³•è¯»å–æ–‡ä»¶ {self.file_path}: {e}ã€‚")
        except Exception as e:
            logger.error(f"ğŸš« åŠ è½½æ•°æ®æ—¶æ„å¤–é”™è¯¯ ({type(e).__name__}): {e}ã€‚")
        return []

    def _backup_corrupted_file(self):
        """
        å¤‡ä»½æŸåçš„æ•°æ®æ–‡ä»¶ã€‚
        æ–°çš„ç­–ç•¥æ˜¯åªä¿ç•™ä¸€ä¸ªåä¸º <file_path>.backup çš„å¤‡ä»½æ–‡ä»¶ã€‚
        """
        if not os.path.exists(self.file_path):
            logger.debug(f"ğŸ› _backup_corrupted_file è°ƒç”¨æ—¶æ–‡ä»¶ {self.file_path} ä¸å­˜åœ¨ï¼Œæ— éœ€å¤‡ä»½ã€‚")
            return

        backup_path = self.file_path + ".backup"

        try:
            logger.info(f"ğŸ”„ å‡†å¤‡å°†æŸåçš„æ–‡ä»¶ {self.file_path} å¤‡ä»½ä¸º {backup_path}ã€‚")

            if os.path.exists(backup_path):
                try:
                    if os.path.isdir(backup_path):
                        logger.error(f"ğŸš« ç›®æ ‡å¤‡ä»½è·¯å¾„ {backup_path} æ˜¯ä¸€ä¸ªç›®å½•ï¼Œæ— æ³•ä½œä¸ºå¤‡ä»½æ–‡ä»¶ã€‚è¯·æ‰‹åŠ¨æ£€æŸ¥å¹¶ç§»é™¤ã€‚")
                        return
                    os.remove(backup_path)
                    logger.info(f"ğŸ—‘ï¸ å·²ç§»é™¤æ—§çš„å¤‡ä»½æ–‡ä»¶: {backup_path}ã€‚")
                except OSError as rm_err:
                    logger.error(f"âš ï¸ æ— æ³•ç§»é™¤å·²å­˜åœ¨çš„å¤‡ä»½æ–‡ä»¶ {backup_path}: {rm_err}ã€‚ç»§ç»­å°è¯•é‡å‘½ååŸæ–‡ä»¶ã€‚")

            os.rename(self.file_path, backup_path)
            logger.info(
                f"âœ… å·²å°†æŸåçš„æ•°æ®æ–‡ä»¶ (åŸè·¯å¾„: {self.file_path}) å¤‡ä»½åˆ° {backup_path}ã€‚ç°åœ¨æœ€å¤šåªæœ‰ä¸€ä¸ªå¤‡ä»½æ–‡ä»¶ã€‚")

        except OSError as bak_err:
            logger.error(f"ğŸš« æ— æ³•å°† {self.file_path} é‡å‘½å/å¤‡ä»½åˆ° {backup_path}: {bak_err}")
        except Exception as e:
            logger.error(f"ğŸ’¥ å¤‡ä»½æ–‡ä»¶ {self.file_path} æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ ({type(e).__name__}): {e}")

    def save_processed_torrents(self, torrents_data: List[Dict[str, Any]]) -> None:
        logger.info(f"ğŸ’¾ æ­£åœ¨å°† {len(torrents_data)} æ¡è®°å½•ä¿å­˜åˆ° {self.file_path}...")
        try:
            dir_name = os.path.dirname(self.file_path)
            if dir_name and not os.path.exists(dir_name):
                os.makedirs(dir_name, exist_ok=True)

            with open(self.file_path, "w", encoding="utf-8") as f:
                json.dump(torrents_data, f, ensure_ascii=False, indent=4)
            logger.info(f"âœ… æ•°æ®æˆåŠŸä¿å­˜åˆ° {self.file_path}ã€‚")
        except IOError as e:
            logger.error(f"ğŸš« ä¿å­˜æ•°æ®åˆ°æ–‡ä»¶ {self.file_path} æ—¶å‘ç”ŸIOé”™è¯¯: {e}")
        except Exception as e:
            logger.error(f"ğŸš« ä¿å­˜æ•°æ®æ—¶æ„å¤–é”™è¯¯ ({type(e).__name__}): {e}")


class TorrentProcessor:
    def __init__(self, config: Config, qbit_manager: QBittorrentManager,
                 mteam_manager: MTeamManager, notifier: TelegramNotifier,
                 data_manager: DataManager):
        self.config = config
        self.qbit_manager = qbit_manager
        self.mteam_manager = mteam_manager
        self.notifier = notifier
        self.data_manager = data_manager
        self.processed_torrents: List[Dict[str, Any]] = []
        self.successfully_added_torrents_info: List[Dict[str, Any]] = []
        self.logger = logging.getLogger(__class__.__name__)

    @staticmethod
    def _generate_torrent_rename_name(torrent_id: str, rss_item: Dict[str, Any],
                                      api_details: Dict[str, Any]) -> str:
        category_rss = rss_item.get('category_rss')
        subtitle_rss = rss_item.get('subtitle_rss')
        rss_title_original = rss_item.get('title', '')
        api_torrent_name = api_details.get("name", "æœªçŸ¥åç§°")
        rename_parts = [f"[{torrent_id}]"]

        if category_rss:
            cleaned_category = re.sub(r'[\\/*?:"<>|]', '', category_rss)[:60].strip()
            if cleaned_category:
                rename_parts.append(f"[{cleaned_category}]")

        supplement_part = ""
        if subtitle_rss:
            temp_subtitle = subtitle_rss.replace(' ', '.')
            supplement_part = re.sub(r'[\\/*?:"<>|]', '', temp_subtitle)[:72].strip()
        elif rss_title_original:
            clean_rss_title = rss_title_original
            if category_rss:
                clean_rss_title = clean_rss_title.replace(f"[{rss_item.get('category_rss')}]", "")
            clean_rss_title = re.sub(r'\[.*?]', '', clean_rss_title).strip()
            clean_rss_title = re.sub(r'\(.*?\)', '', clean_rss_title).strip()
            title_elements = clean_rss_title.split('-')
            if len(title_elements) > 1 and title_elements[-1].isalpha() and len(title_elements[-1]) < 10:
                clean_rss_title = "-".join(title_elements[:-1]).strip()
            else:
                clean_rss_title = clean_rss_title.strip()
            if clean_rss_title:
                temp_title_part = clean_rss_title.replace(' ', '.')
                supplement_part = re.sub(r'[\\/*?:"<>|]', '', temp_title_part)[:72].strip()
        if supplement_part:
            rename_parts.append(f"[{supplement_part}]")

        if len(rename_parts) <= ("Category" in str(rename_parts)) + 1 and api_torrent_name:
            name_part_match = re.match(r'^([^\[]+)', api_torrent_name)
            name_part_for_rename = name_part_match.group(1).strip() if name_part_match else api_torrent_name.strip()
            name_part_for_rename = re.sub(r'[\\/*?:"<>|]', '', name_part_for_rename)
            name_part_for_rename = name_part_for_rename.replace(' ', '.')[:50].strip()
            if name_part_for_rename and name_part_for_rename.lower() not in "".join(rename_parts).lower():
                rename_parts.append(f"[{name_part_for_rename}]")

        rename_value = "".join(rename_parts)
        rename_value = rename_value.replace("][", "][")
        rename_value = re.sub(r'\.+', '.', rename_value)
        rename_value = rename_value.strip('. ')

        test_val = rename_value.replace(f"[{torrent_id}]", "").replace("[]", "").strip(" .")
        if not test_val:
            fallback_api_name = re.sub(r'[\\/*?:"<>|]', '', api_torrent_name).replace(' ', '.')[:60].strip(".-_ ")
            rename_value = f"[{torrent_id}][{fallback_api_name}]"
        return rename_value[:200]

    async def run(self) -> int:
        self.logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œåˆ·æµå¤„ç†ä»»åŠ¡...")
        self.processed_torrents = self.data_manager.load_processed_torrents()
        self.successfully_added_torrents_info.clear()

        if not self.qbit_manager.client or not self.qbit_manager.client.is_logged_in:
            self.logger.error("ğŸš« qBittorrent å®¢æˆ·ç«¯ä¸å¯ç”¨ã€‚è„šæœ¬æ— æ³•ç»§ç»­ã€‚")
            return 0

        unfinished_downloads_count = self.qbit_manager.get_unfinished_torrents_count()
        if unfinished_downloads_count is None:
            self.logger.warning("âš ï¸ æ— æ³•è·å–qBittorrentæœªå®Œæˆä»»åŠ¡æ•°ï¼Œå°†è·³è¿‡æ­¤æ£€æŸ¥å¹¶ç»§ç»­ã€‚")
        elif unfinished_downloads_count > self.config.MAX_UNFINISHED_DOWNLOADS:
            run_warning_msg = (f"qBittorrentä¸­æœªå®Œæˆçš„ä¸‹è½½ä»»åŠ¡æ•°é‡ ({unfinished_downloads_count}) "
                               f"å·²è¶…è¿‡è®¾å®šçš„é™åˆ¶ ({self.config.MAX_UNFINISHED_DOWNLOADS})ã€‚")
            self.logger.warning(f"ğŸš¦ {run_warning_msg} æœ¬è½®åˆ·æµå°†æš‚åœã€‚")
            await self.notifier.send_message(
                self.notifier.format_max_unfinished_torrents_warning(unfinished_downloads_count,
                                                                     self.config.MAX_UNFINISHED_DOWNLOADS)
            )
            self.data_manager.save_processed_torrents(self.processed_torrents)
            return 0

        current_disk_space = self.qbit_manager.get_free_disk_space()
        if current_disk_space is None:
            self.logger.error("ğŸš« æ— æ³•ç¡®å®šç£ç›˜ç©ºé—´ã€‚è„šæœ¬æ— æ³•ç»§ç»­ã€‚")
            await self.notifier.send_message(self.notifier.format_script_status("error", details="æ— æ³•è·å–ç£ç›˜ç©ºé—´"))
            self.data_manager.save_processed_torrents(self.processed_torrents)
            return 0

        space_limit_bytes = Utils.convert_gb_to_bytes(self.config.DISK_SPACE_LIMIT_GB)
        if current_disk_space <= space_limit_bytes:
            msg = f"åˆå§‹ç£ç›˜ç©ºé—´ ({Utils.format_size(current_disk_space)}) å·²ä½äºé™åˆ¶ ({Utils.format_size(space_limit_bytes)})ã€‚æ·»åŠ æ–°ç§å­å¤±è´¥ã€‚"
            self.logger.warning(f"ğŸ“‰ {msg}")
            await self.notifier.send_message(self.notifier.format_script_status("warning_disk_space", details=msg))
            self.data_manager.save_processed_torrents(self.processed_torrents)
            return 0

        rss_items = self.mteam_manager.get_rss_feed_items()
        if not rss_items:
            self.logger.info("â„¹ï¸ RSSè®¢é˜…æºä¸­æœªæ‰¾åˆ°é¡¹ç›®æˆ–åŠ è½½å¤±è´¥ã€‚")
            self.data_manager.save_processed_torrents(self.processed_torrents)
            return 0

        min_size_bytes = Utils.convert_gb_to_bytes(self.config.MIN_TORRENT_SIZE_GB)
        max_size_bytes = Utils.convert_gb_to_bytes(self.config.MAX_TORRENT_SIZE_GB)
        now_localized = Utils.get_current_time_localized(self.config.LOCAL_TIMEZONE)

        for item in rss_items:
            torrent_id = item["id"]
            self.logger.debug(f"ğŸ” å¤„ç†RSSé¡¹ç›®: ID={torrent_id}, æ ‡é¢˜='{item.get('title', 'N/A')[:60]}...'")

            if any(str(p_torrent.get("id")) == str(torrent_id) for p_torrent in self.processed_torrents):
                self.logger.debug(f"âœ… ç§å­ID {torrent_id}: å·²å¤„ç†è¿‡ï¼Œè·³è¿‡ã€‚")
                continue

            try:
                publish_time_naive = date_parser.parse(item["publish_time_str"], tzinfos=self.config.TZ_INFOS)
                if publish_time_naive.tzinfo is None or publish_time_naive.tzinfo.utcoffset(publish_time_naive) is None:
                    publish_time_aware = self.config.LOCAL_TIMEZONE.localize(publish_time_naive)
                else:
                    publish_time_aware = publish_time_naive.astimezone(self.config.LOCAL_TIMEZONE)
            except Exception as e:
                self.logger.warning(
                    f"âš ï¸ ç§å­ID {torrent_id}: è§£æå‘å¸ƒæ—¶é—´ '{item.get('publish_time_str')}' å¤±è´¥: {e}ã€‚è·³è¿‡ã€‚")
                continue

            if (now_localized - publish_time_aware).total_seconds() > self.config.SEED_PUBLISH_BEFORE_SECONDS:
                self.logger.debug(
                    f"â° ç§å­ID {torrent_id}: å‘å¸ƒæ—¶é—´ ({publish_time_aware}) è¿‡æ—©ï¼Œå·²è¶…è¿‡ {self.config.SEED_PUBLISH_BEFORE_HOURS} å°æ—¶é™åˆ¶ã€‚è·³è¿‡ã€‚")
                continue

            rss_torrent_size = item.get("size_bytes_rss", -1)
            if rss_torrent_size > 0:
                if not (min_size_bytes <= rss_torrent_size <= max_size_bytes):
                    self.logger.debug(
                        f"ğŸ“ ç§å­ID {torrent_id}: RSSå¤§å° {Utils.format_size(rss_torrent_size)} è¶…å‡ºèŒƒå›´ "
                        f"({Utils.format_size(min_size_bytes)} - {Utils.format_size(max_size_bytes)})ã€‚è·³è¿‡ã€‚")
                    continue
                if (current_disk_space - rss_torrent_size) < space_limit_bytes:
                    self.logger.debug(
                        f"ğŸ“‰ ç§å­ID {torrent_id}: RSSå¤§å° {Utils.format_size(rss_torrent_size)} å°†å¯¼è‡´ç£ç›˜ç©ºé—´ "
                        f"({Utils.format_size(current_disk_space - rss_torrent_size)}) ä½äºé™åˆ¶ "
                        f"({Utils.format_size(space_limit_bytes)})ã€‚è·³è¿‡ã€‚")
                    continue

            await Utils.random_delay_async(self.config.API_REQUEST_DELAY_MIN, self.config.API_REQUEST_DELAY_MAX)
            details = self.mteam_manager.get_torrent_details(torrent_id)
            if not details:
                self.logger.warning(f"âš ï¸ ç§å­ID {torrent_id}: è·å–MTeamè¯¦ç»†ä¿¡æ¯å¤±è´¥ã€‚è·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "api_detail_failed", "time": now_localized.isoformat()})
                continue

            api_torrent_name = details.get("name", "æœªçŸ¥åç§°")
            api_torrent_size = details.get("size", 0)
            if api_torrent_size == 0:
                self.logger.warning(f"âš ï¸ ç§å­ID {torrent_id} ({api_torrent_name}): APIè¿”å›å¤§å°ä¸º0ï¼Œå¯èƒ½æ— æ•ˆï¼Œè·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "api_zero_size", "time": now_localized.isoformat()})
                continue

            if not (min_size_bytes <= api_torrent_size <= max_size_bytes):
                self.logger.debug(
                    f"ğŸ“ ç§å­ID {torrent_id} ({api_torrent_name}): APIå¤§å° {Utils.format_size(api_torrent_size)} "
                    f"ä¸ç¬¦åˆå¤§å°èŒƒå›´ ({Utils.format_size(min_size_bytes)} - {Utils.format_size(max_size_bytes)})ã€‚è·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "size_mismatch_api", "time": now_localized.isoformat()})
                continue

            if (current_disk_space - api_torrent_size) < space_limit_bytes:
                self.logger.info(
                    f"ğŸ“‰ ç§å­ID {torrent_id} ({api_torrent_name}): APIå¤§å° {Utils.format_size(api_torrent_size)} "
                    f"å°†å¯¼è‡´ç£ç›˜ç©ºé—´ä¸è¶³ã€‚å‰©ä½™: {Utils.format_size(current_disk_space)}, é™åˆ¶: {Utils.format_size(space_limit_bytes)}ã€‚")
                if not self.successfully_added_torrents_info:
                    await self.notifier.send_message(self.notifier.format_script_status("warning_disk_space",
                                                                                        details=f"å°è¯•æ·»åŠ  {api_torrent_name} ({Utils.format_size(api_torrent_size)}) å°†å¯¼è‡´ç©ºé—´ä¸è¶³ã€‚å‰©ä½™ç©ºé—´æ£€æŸ¥æ— æ³•é€šè¿‡ã€‚"))
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "disk_space_insufficient_api", "time": now_localized.isoformat()})
                continue

            torrent_discount = details.get("discount", "UNKNOWN")
            if torrent_discount not in ["FREE", "_2X_FREE"]:
                self.logger.debug(f"ğŸ’° ç§å­ID {torrent_id} ({api_torrent_name}): éå…è´¹ ({torrent_discount})ã€‚è·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "not_free", "time": now_localized.isoformat()})
                continue

            if details.get("discount_end_time"):
                min_required_free_end_time = now_localized + timedelta(seconds=self.config.SEED_FREE_TIME_SECONDS)
                if details["discount_end_time"] < min_required_free_end_time:
                    self.logger.debug(
                        f"â³ ç§å­ID {torrent_id} ({api_torrent_name}): å…è´¹æ—¶é—´ ({details['discount_end_time']}) "
                        f"ä¸è¶³ {self.config.SEED_FREE_TIME_HOURS} å°æ—¶ã€‚è·³è¿‡ã€‚")
                    self.processed_torrents.append(
                        {"id": torrent_id, "status": "free_time_insufficient", "time": now_localized.isoformat()})
                    continue

            seeders = details.get("seeders", 0)
            leechers = details.get("leechers", 0)
            if seeders <= 0:
                self.logger.debug(f"ğŸŒ± ç§å­ID {torrent_id} ({api_torrent_name}): æ— (æˆ–0)åšç§è€… ({seeders})ã€‚è·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "no_seeders", "time": now_localized.isoformat()})
                continue

            current_ls_ratio = (leechers / seeders) if seeders > 0 else float('inf')
            if current_ls_ratio < self.config.DOWNLOADERS_TO_SEEDERS_RATIO:
                self.logger.debug(
                    f"ğŸ“Š ç§å­ID {torrent_id} ({api_torrent_name}): L/Sæ¯”ä¾‹ ({leechers}/{seeders} = {current_ls_ratio:.2f}) "
                    f"ä½äºè®¾å®šé˜ˆå€¼ {self.config.DOWNLOADERS_TO_SEEDERS_RATIO}ã€‚è·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "ls_ratio_low", "time": now_localized.isoformat()})
                continue

            ls_ratio_str = f"{leechers}/{seeders} = {current_ls_ratio:.2f}"
            self.logger.info(
                f"ğŸ‰ ç§å­ID {torrent_id} ({api_torrent_name}): æ¡ä»¶æ»¡è¶³ï¼Œå‡†å¤‡ä¸‹è½½ã€‚L/S: {ls_ratio_str}, å¤§å°: {Utils.format_size(api_torrent_size)}")

            rename_value = self._generate_torrent_rename_name(torrent_id, item, details)
            self.logger.info(f"â„¹ï¸ ç§å­ID {torrent_id}: è®¡åˆ’é‡å‘½åä¸º '{rename_value}'")

            await Utils.random_delay_async(self.config.API_REQUEST_DELAY_MIN, self.config.API_REQUEST_DELAY_MAX)
            download_url = self.mteam_manager.get_torrent_download_url(torrent_id)
            if not download_url:
                self.logger.warning(f"âš ï¸ ç§å­ID {torrent_id} ({api_torrent_name}): è·å–ä¸‹è½½é“¾æ¥å¤±è´¥ã€‚è·³è¿‡ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "download_url_failed", "time": now_localized.isoformat()})
                continue

            if self.qbit_manager.add_torrent_by_url(download_url, rename_value=rename_value):
                self.logger.info(f"âœ… å·²æˆåŠŸä¸ºç§å­ID {torrent_id} ({api_torrent_name}) å‘èµ·ä¸‹è½½ã€‚")
                self.successfully_added_torrents_info.append({
                    "mteam_id": torrent_id, "name": api_torrent_name, "renamed_to": rename_value,
                    "size_bytes": api_torrent_size, "discount": torrent_discount, "ls_ratio": ls_ratio_str
                })
                self.processed_torrents.append({
                    "id": torrent_id, "name": api_torrent_name,
                    "renamed_name_in_qb": rename_value,
                    "added_time": now_localized.isoformat(),
                    "size_bytes": api_torrent_size,
                    "status": "added_to_qb"
                })
                current_disk_space -= api_torrent_size

                if current_disk_space <= space_limit_bytes:
                    msg = (f"æ·»åŠ ç§å­ '{api_torrent_name}' ({Utils.format_size(api_torrent_size)}) åï¼Œ"
                           f"ç£ç›˜ç©ºé—´ ({Utils.format_size(current_disk_space)}) å·²ä½äºé™åˆ¶ ({Utils.format_size(space_limit_bytes)})ã€‚"
                           f"åœæ­¢æ·»åŠ æ›´å¤šç§å­ã€‚")
                    self.logger.info(f"ğŸ“‰ {msg}")
                    await self.notifier.send_message(
                        self.notifier.format_script_status("warning_disk_space", details=msg))
                    break
            else:
                self.logger.error(f"ğŸš« ç§å­ID {torrent_id} ({api_torrent_name}): æ·»åŠ åˆ°qBittorrentå¤±è´¥ã€‚")
                self.processed_torrents.append(
                    {"id": torrent_id, "status": "qb_add_failed", "time": now_localized.isoformat()})

        final_processed_map = {}
        for record in self.processed_torrents:
            existing_record = final_processed_map.get(record['id'])
            if not existing_record or \
                    (record.get('status') == 'added_to_qb' and existing_record.get('status') != 'added_to_qb') or \
                    (record.get('time', '') > existing_record.get('time', '')):
                final_processed_map[record['id']] = record
        self.processed_torrents = list(final_processed_map.values())

        self.data_manager.save_processed_torrents(self.processed_torrents)
        return len(self.successfully_added_torrents_info)


async def main():
    script_start_time = time.monotonic()
    logger.info(f"ğŸ ===== è„šæœ¬æ‰§è¡Œå¼€å§‹: {datetime.now(pytz.utc).isoformat()} =====")

    notifier_instance: Optional[TelegramNotifier] = None
    qbit_manager_instance: Optional[QBittorrentManager] = None
    exit_code = 0

    try:
        config_instance = Config()
        notifier_instance = TelegramNotifier(config_instance)
        # await notifier_instance.send_message(notifier_instance.format_script_status("start"))
        qbit_manager_instance = QBittorrentManager(config_instance)
        if not qbit_manager_instance.client:
            raise ConnectionError("qBittorrent å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥æˆ–æœªè¿æ¥ã€‚")

        mteam_manager = MTeamManager(config_instance)
        data_manager = DataManager(config_instance)
        processor = TorrentProcessor(config_instance, qbit_manager_instance, mteam_manager, notifier_instance,
                                     data_manager)
        num_added = await processor.run()

        duration = time.monotonic() - script_start_time
        summary_message = notifier_instance.format_bulk_torrent_add_success(
            processor.successfully_added_torrents_info, duration
        )
        if summary_message:
            await notifier_instance.send_message(summary_message)

        if num_added == 0 and not processor.successfully_added_torrents_info:
            logger.info("â„¹ï¸ æœ¬è½®æœªæ·»åŠ ä»»ä½•æ–°ç§å­ã€‚")
        else:
            logger.info(f"âœ… æœ¬è½®æˆåŠŸæ·»åŠ  {num_added} ä¸ªæ–°ç§å­ã€‚")

    except (LoginFailed, APIConnectionError, ConnectionError) as e:
        logger.critical(f"ğŸš« qBittorrent è¿æ¥æˆ–ç™»å½•å¤±è´¥: {e}ã€‚è„šæœ¬ä¸­æ­¢ã€‚")
        if notifier_instance: await notifier_instance.send_message(
            notifier_instance.format_script_status("error", details=f"qBittorrentè¿æ¥é—®é¢˜: {e}"))
        exit_code = 1
    except ValueError as e:
        logger.critical(f"ğŸš« åˆå§‹åŒ–ç®¡ç†å™¨æ—¶å‘ç”Ÿé…ç½®æˆ–æ•°å€¼é”™è¯¯: {e}ã€‚è„šæœ¬ä¸­æ­¢ã€‚")
        if notifier_instance: await notifier_instance.send_message(
            notifier_instance.format_script_status("error", details=f"é…ç½®/åˆå§‹åŒ–é”™è¯¯: {e}"))
        exit_code = 1
    except SystemExit as e:
        logger.critical(f"ğŸš« é…ç½®åˆå§‹åŒ–å¤±è´¥å¯¼è‡´è„šæœ¬ä¸­æ­¢: {e}")
        if notifier_instance and notifier_instance.bot:
            await notifier_instance.send_message(
                notifier_instance.format_script_status("error", details=f"ä¸¥é‡é…ç½®é”™è¯¯å¯¼è‡´ä¸­æ­¢: {e}")
            )
        else:
            if temp_tg_token and temp_tg_chat_id:
                try:
                    main_emergency_notifier = TelegramNotifier(Config())
                    if main_emergency_notifier.bot:
                        await main_emergency_notifier.send_message(
                            main_emergency_notifier.format_script_status("error", details=f"ä¸¥é‡é…ç½®é”™è¯¯å¯¼è‡´ä¸­æ­¢: {e}")
                        )
                except Exception as tg_init_err:
                    logger.error(f"ğŸš« åˆ›å»ºæˆ–å‘é€Telegramé€šçŸ¥æ—¶å‘ç”Ÿé”™è¯¯: {tg_init_err}")
        exit_code = 1
    except Exception as e:
        logger.critical(f"ğŸš« æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªæ•è·çš„ä¸¥é‡é”™è¯¯ ({type(e).__name__}): {e}", exc_info=True)
        if notifier_instance: await notifier_instance.send_message(
            notifier_instance.format_script_status("error",
                                                   details=f"æœªæ•è·çš„ä¸¥é‡é”™è¯¯: {type(e).__name__} - {str(e)[:100]}..."))
        exit_code = 1
    finally:
        if qbit_manager_instance:
            qbit_manager_instance.disconnect()

        elapsed_time = time.monotonic() - script_start_time
        if exit_code == 0:
            logger.info(f"ğŸ‰ ===== è„šæœ¬æ‰§è¡Œå®Œæ¯•ï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’. =====")
        else:
            logger.error(f"ğŸš« ===== è„šæœ¬å› é”™è¯¯ä¸­æ­¢ï¼Œè€—æ—¶ {elapsed_time:.2f} ç§’. =====")

        if notifier_instance and notifier_instance.bot:
            await asyncio.sleep(2)


if __name__ == "__main__":
    required_env_vars = ["MT_APIKEY", "MT_RSS_URL", "QBIT_HOST", "QBIT_USERNAME", "QBIT_PASSWORD"]
    missing_vars = [var for var in required_env_vars if not os.environ.get(var)]

    if missing_vars:
        error_message = f"é”™è¯¯ï¼šä»¥ä¸‹å¿…è¦çš„ç¯å¢ƒå˜é‡æœªè®¾ç½®: {', '.join(missing_vars)}ã€‚è¯·è®¾ç½®åå†è¿è¡Œã€‚"
        print(error_message)
        logger.critical(error_message)

        temp_tg_token = os.environ.get("TG_BOT_TOKEN")
        temp_tg_chat_id = os.environ.get("TG_CHAT_ID")
        if temp_tg_token and temp_tg_chat_id:
            try:
                emergency_notifier = TelegramNotifier(Config())
                if emergency_notifier.bot:
                    async def notify_critical_env_error():
                        await emergency_notifier.send_message(
                            emergency_notifier.format_script_status("error",
                                                                    details=f"ç¯å¢ƒå˜é‡ç¼ºå¤±: {', '.join(missing_vars)}")
                        )
                        await asyncio.sleep(1)


                    asyncio.run(notify_critical_env_error())
            except Exception as tg_err:
                print(f"å‘é€Telegramé€šçŸ¥å¤±è´¥: {tg_err}")
        sys.exit(1)

    if not os.environ.get("TG_BOT_TOKEN") or not os.environ.get("TG_CHAT_ID"):
        warning_msg = "è­¦å‘Šï¼šTelegram ç¯å¢ƒå˜é‡ TG_BOT_TOKEN æˆ– TG_CHAT_ID æœªè®¾ç½®ï¼Œé€šçŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨ã€‚"
        print(warning_msg)
        logger.warning(warning_msg)

    asyncio.run(main())
